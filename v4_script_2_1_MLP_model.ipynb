{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceeebd00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T01:49:14.236416Z",
     "start_time": "2023-01-21T01:49:13.734124Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from os import getcwd \n",
    "from os.path import exists\n",
    "\n",
    "getcwd() # current working directory\n",
    "\n",
    "version = 'v4'\n",
    "update = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92892710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T01:49:14.866733Z",
     "start_time": "2023-01-21T01:49:14.238413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of proteins:       272\n",
      "total number of samples:        41264\n",
      "total number of positive sites: 521\n",
      "total number of negative sites: 40743\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>SEQ</th>\n",
       "      <th>SS</th>\n",
       "      <th>ASA</th>\n",
       "      <th>Phi</th>\n",
       "      <th>Psi</th>\n",
       "      <th>Theta(i-1=&gt;i+1)</th>\n",
       "      <th>Tau(i-2=&gt;i+2)</th>\n",
       "      <th>HSE_alpha_up</th>\n",
       "      <th>HSE_alpha_down</th>\n",
       "      <th>...</th>\n",
       "      <th>side_3</th>\n",
       "      <th>side_4</th>\n",
       "      <th>side_5</th>\n",
       "      <th>nAli</th>\n",
       "      <th>nPos</th>\n",
       "      <th>nS/nT</th>\n",
       "      <th>Proline</th>\n",
       "      <th>phi_psi</th>\n",
       "      <th>positivity</th>\n",
       "      <th>protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>103.3</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>132.1</td>\n",
       "      <td>117.6</td>\n",
       "      <td>-150.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>cycle</td>\n",
       "      <td>small</td>\n",
       "      <td>pro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>A2ABU4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-87.4</td>\n",
       "      <td>138.5</td>\n",
       "      <td>115.2</td>\n",
       "      <td>-125.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>16.7</td>\n",
       "      <td>...</td>\n",
       "      <td>small</td>\n",
       "      <td>very_small</td>\n",
       "      <td>gly</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>A2ABU4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>56.1</td>\n",
       "      <td>-89.9</td>\n",
       "      <td>142.4</td>\n",
       "      <td>116.8</td>\n",
       "      <td>121.2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>normal</td>\n",
       "      <td>pro</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>A2ABU4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>75.5</td>\n",
       "      <td>-82.7</td>\n",
       "      <td>22.5</td>\n",
       "      <td>104.9</td>\n",
       "      <td>-107.4</td>\n",
       "      <td>5.9</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>very_small</td>\n",
       "      <td>normal</td>\n",
       "      <td>very_small</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>A2ABU4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>78.2</td>\n",
       "      <td>-96.3</td>\n",
       "      <td>112.1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>84.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>very_small</td>\n",
       "      <td>cycle</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>A2ABU4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41259</th>\n",
       "      <td>2876</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>76.2</td>\n",
       "      <td>-95.6</td>\n",
       "      <td>138.6</td>\n",
       "      <td>117.8</td>\n",
       "      <td>-135.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>very_small</td>\n",
       "      <td>long</td>\n",
       "      <td>small</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>Q9Y520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41260</th>\n",
       "      <td>2881</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>58.2</td>\n",
       "      <td>-99.5</td>\n",
       "      <td>90.7</td>\n",
       "      <td>111.0</td>\n",
       "      <td>-161.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>...</td>\n",
       "      <td>small</td>\n",
       "      <td>long</td>\n",
       "      <td>pro</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>Q9Y520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41261</th>\n",
       "      <td>2891</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>80.3</td>\n",
       "      <td>-102.2</td>\n",
       "      <td>131.1</td>\n",
       "      <td>116.5</td>\n",
       "      <td>-164.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>...</td>\n",
       "      <td>small</td>\n",
       "      <td>long</td>\n",
       "      <td>small</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>Q9Y520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41262</th>\n",
       "      <td>2894</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>106.7</td>\n",
       "      <td>-91.4</td>\n",
       "      <td>100.3</td>\n",
       "      <td>109.1</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>Q9Y520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41263</th>\n",
       "      <td>2896</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>98.4</td>\n",
       "      <td>-91.9</td>\n",
       "      <td>113.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>Q9Y520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41264 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          # SEQ SS    ASA    Phi    Psi  Theta(i-1=>i+1)  Tau(i-2=>i+2)  \\\n",
       "0         2   T  C  103.3 -102.0  132.1            117.6         -150.0   \n",
       "1         6   S  C   60.0  -87.4  138.5            115.2         -125.9   \n",
       "2         9   S  C   56.1  -89.9  142.4            116.8          121.2   \n",
       "3        16   S  C   75.5  -82.7   22.5            104.9         -107.4   \n",
       "4        18   T  C   78.2  -96.3  112.1            112.0           84.6   \n",
       "...     ...  .. ..    ...    ...    ...              ...            ...   \n",
       "41259  2876   T  C   76.2  -95.6  138.6            117.8         -135.9   \n",
       "41260  2881   T  C   58.2  -99.5   90.7            111.0         -161.6   \n",
       "41261  2891   T  C   80.3 -102.2  131.1            116.5         -164.4   \n",
       "41262  2894   T  C  106.7  -91.4  100.3            109.1         -163.0   \n",
       "41263  2896   S  C   98.4  -91.9  113.0            110.0          100.4   \n",
       "\n",
       "       HSE_alpha_up  HSE_alpha_down  ...      side_3      side_4      side_5  \\\n",
       "0               3.8            13.9  ...       cycle       small         pro   \n",
       "1               7.8            16.7  ...       small  very_small         gly   \n",
       "2               8.2            13.9  ...      normal         pro      normal   \n",
       "3               5.9            14.2  ...  very_small      normal  very_small   \n",
       "4               5.8            13.7  ...  very_small       cycle        long   \n",
       "...             ...             ...  ...         ...         ...         ...   \n",
       "41259           8.8            13.9  ...  very_small        long       small   \n",
       "41260          11.6            16.2  ...       small        long         pro   \n",
       "41261           7.0            14.3  ...       small        long       small   \n",
       "41262           3.1             9.1  ...        None        None        None   \n",
       "41263           2.1             6.2  ...        None        None        None   \n",
       "\n",
       "       nAli nPos nS/nT Proline phi_psi positivity protein  \n",
       "0         0    0     3       0   alpha          0  A2ABU4  \n",
       "1         2    0     4       1   alpha          0  A2ABU4  \n",
       "2         1    0     5       0   alpha          0  A2ABU4  \n",
       "3         2    0     4       0   other          0  A2ABU4  \n",
       "4         1    0     3       0   alpha          0  A2ABU4  \n",
       "...     ...  ...   ...     ...     ...        ...     ...  \n",
       "41259     2    0     3       0   alpha          0  Q9Y520  \n",
       "41260     2    0     4       0   other          0  Q9Y520  \n",
       "41261     2    1     4       0   alpha          0  Q9Y520  \n",
       "41262     0    0     3       0   alpha          0  Q9Y520  \n",
       "41263     0    1     3       0   alpha          0  Q9Y520  \n",
       "\n",
       "[41264 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_name = \"v4_data_all_sites.csv\"\n",
    "dataset = pd.read_csv(load_name)\n",
    "\n",
    "ST_dataset = dataset[(dataset['SEQ']=='S') | (dataset['SEQ']=='T')].reset_index(drop=True)\n",
    "ST_positive = ST_dataset[ST_dataset['positivity']==1]\n",
    "ST_negative = ST_dataset[ST_dataset['positivity']==0]\n",
    "\n",
    "print(\"total number of proteins:      \", len(ST_dataset.protein.unique()))\n",
    "print(\"total number of samples:       \", len(ST_dataset))\n",
    "print(\"total number of positive sites:\", len(ST_positive))\n",
    "print(\"total number of negative sites:\", len(ST_negative))\n",
    "display(ST_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb592ccc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T01:49:14.898672Z",
     "start_time": "2023-01-21T01:49:14.867732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41264 entries, 0 to 41263\n",
      "Data columns (total 27 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   #                41264 non-null  int64  \n",
      " 1   SEQ              41264 non-null  object \n",
      " 2   SS               41264 non-null  object \n",
      " 3   ASA              41264 non-null  float64\n",
      " 4   Phi              41264 non-null  float64\n",
      " 5   Psi              41264 non-null  float64\n",
      " 6   Theta(i-1=>i+1)  41264 non-null  float64\n",
      " 7   Tau(i-2=>i+2)    41264 non-null  float64\n",
      " 8   HSE_alpha_up     41264 non-null  float64\n",
      " 9   HSE_alpha_down   41264 non-null  float64\n",
      " 10  P(C)             41264 non-null  float64\n",
      " 11  P(H)             41264 non-null  float64\n",
      " 12  P(E)             41264 non-null  float64\n",
      " 13  flexibility      41264 non-null  float64\n",
      " 14  side_-1          41264 non-null  object \n",
      " 15  side_1           41264 non-null  object \n",
      " 16  side_2           41264 non-null  object \n",
      " 17  side_3           41264 non-null  object \n",
      " 18  side_4           41264 non-null  object \n",
      " 19  side_5           41264 non-null  object \n",
      " 20  nAli             41264 non-null  int64  \n",
      " 21  nPos             41264 non-null  int64  \n",
      " 22  nS/nT            41264 non-null  int64  \n",
      " 23  Proline          41264 non-null  int64  \n",
      " 24  phi_psi          41264 non-null  object \n",
      " 25  positivity       41264 non-null  int64  \n",
      " 26  protein          41264 non-null  object \n",
      "dtypes: float64(11), int64(6), object(10)\n",
      "memory usage: 8.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ST_dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8c5cd",
   "metadata": {},
   "source": [
    "# Case 1: without window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d7578e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T01:49:14.930562Z",
     "start_time": "2023-01-21T01:49:14.900643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41264, 16)\n",
      "(41264, 1)\n",
      "\n",
      "x columns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                 ASA\n",
       "1                 Phi\n",
       "2                 Psi\n",
       "3     Theta(i-1=>i+1)\n",
       "4       Tau(i-2=>i+2)\n",
       "5        HSE_alpha_up\n",
       "6      HSE_alpha_down\n",
       "7                P(C)\n",
       "8                P(H)\n",
       "9                P(E)\n",
       "10        flexibility\n",
       "11              SEQ_S\n",
       "12              SEQ_T\n",
       "13               SS_C\n",
       "14               SS_E\n",
       "15               SS_H\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_cat = ['SEQ', 'SS']\n",
    "x_cts = ['ASA', 'Phi', 'Psi', 'Theta(i-1=>i+1)', 'Tau(i-2=>i+2)', 'HSE_alpha_up', 'HSE_alpha_down', \n",
    "         'P(C)', 'P(H)', 'P(E)', 'flexibility']\n",
    "y_label = ['positivity']\n",
    "\n",
    "data_x = pd.get_dummies(ST_dataset[x_cts+x_cat], columns=x_cat)\n",
    "data_y = ST_dataset[y_label]\n",
    "\n",
    "print(data_x.shape)\n",
    "print(data_y.shape)\n",
    "\n",
    "print(\"\\nx columns:\")\n",
    "display(pd.Series(data_x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8abb4e7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T01:49:15.467445Z",
     "start_time": "2023-01-21T01:49:14.931560Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def stratified_split(data_x, data_y, test_size=0.2, n_splits=1, random_state=1, dtype='arr'):\n",
    "\n",
    "    split = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    train_x, train_y, test_x, test_y  = [], [], [], []\n",
    "    if dtype=='df':\n",
    "        data_x = data_x.values\n",
    "        data_y = data_y.values\n",
    "    \n",
    "    for train_index, test_index in split.split(data_x, data_y):\n",
    "        train_x.append(data_x[train_index])\n",
    "        train_y.append(data_y[train_index])\n",
    "\n",
    "        test_x.append(data_x[test_index])\n",
    "        test_y.append(data_y[test_index])\n",
    "        \n",
    "    print(\"train/test dataset\")\n",
    "    print(\"train:\", train_x[0].shape, train_y[0].shape)\n",
    "    print(\"test:\", test_x[0].shape, test_y[0].shape)\n",
    "    \n",
    "    if n_splits == 1:\n",
    "        return train_x[0],train_y[0], test_x[0], test_y[0]\n",
    "    else:\n",
    "        return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1df0358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T01:49:15.752287Z",
     "start_time": "2023-01-21T01:49:15.467958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.012024048096192367 1.124248496993988\n",
      "2th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: 0.0 1.0173697270471465\n",
      "3th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.01669449081803005 1.0068027210884352\n",
      "4th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.010695187165775383 1.0\n",
      "5th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.004077471967380227 1.0\n",
      "6th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: 0.0 1.1227722772277227\n",
      "7th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.01839464882943134 1.0068027210884352\n",
      "8th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.01669449081803005 1.0765027322404372\n",
      "9th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.001959137979289081 1.0134680134680134\n",
      "10th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.01669449081803005 1.0\n"
     ]
    }
   ],
   "source": [
    "### split data into train/test dataset ###\n",
    "test_size = 0.2\n",
    "n_splits = 10\n",
    "random_state = 1\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "arr_x, arr_y = data_x.values, data_y.values # convert dataframe to nd-array \n",
    "\n",
    "i=1\n",
    "train_idx_list, train_x_list, train_y_list, test_idx_list, test_x_list, test_y_list = [], [], [], [], [], []\n",
    "for train_index, test_index in split.split(arr_x, arr_y):\n",
    "    train_x = arr_x[train_index]\n",
    "    train_y = arr_y[train_index]\n",
    "    test_x = arr_x[test_index]\n",
    "    test_y = arr_y[test_index]\n",
    "    \n",
    "    train_cts = train_x[:,:len(x_cts)]\n",
    "    test_cts  = test_x[:,:len(x_cts)]\n",
    "    \n",
    "    x_min = train_cts.min(axis=0)\n",
    "    x_max = train_cts.max(axis=0)\n",
    "    \n",
    "    train_x[:,:len(x_cts)] = (train_cts-x_min)/(x_max-x_min)\n",
    "    test_x[:,:len(x_cts)] = (test_cts-x_min)/(x_max-x_min)\n",
    "    \n",
    "    print(f\"{i}th iteration\")\n",
    "    print(\"train:\", train_x.shape, train_y.shape, \"check scale:\", train_x.min(), train_x.max())\n",
    "    print(\"test: \", test_x.shape, test_y.shape, \"check scale:\", test_x.min(), test_x.max())\n",
    "    \n",
    "    train_idx_list.append(train_index)\n",
    "    train_x_list.append(train_x)\n",
    "    train_y_list.append(train_y)\n",
    "    \n",
    "    test_idx_list.append(test_index)\n",
    "    test_x_list.append(test_x)\n",
    "    test_y_list.append(test_y)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d731b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T01:49:16.116193Z",
     "start_time": "2023-01-21T01:49:15.752811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up-sampled train dataset: (65188, 16) (65188, 1)\n",
      "test dataset: (8253, 16) (8253, 1)\n"
     ]
    }
   ],
   "source": [
    "## upsampling dataset \n",
    "import random\n",
    "random_state = random_state\n",
    "\n",
    "upsample_x_list, upsample_y_list = [], []\n",
    "for train_x, train_y in zip(train_x_list, train_y_list):\n",
    "    index_pos = np.where(train_y == 1)[0]\n",
    "    index_neg = np.where(train_y == 0)[0]\n",
    "\n",
    "    random.seed(random_state)\n",
    "    up_index = [random.choice(index_pos) for _ in range(len(index_neg))] # get samples from positive sites as much as the number of negative sites\n",
    "\n",
    "    upsample_pos_x = train_x[up_index]\n",
    "    upsample_pos_y = train_y[up_index]\n",
    "    sample_neg_x = train_x[index_neg]\n",
    "    sample_neg_y = train_y[index_neg]\n",
    "\n",
    "    sample_x = np.concatenate([upsample_pos_x, sample_neg_x], axis=0)\n",
    "    sample_y = np.concatenate([upsample_pos_y, sample_neg_y], axis=0)\n",
    "\n",
    "    shuffle_index = np.arange(len(sample_x))\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    sample_x = sample_x[shuffle_index]\n",
    "    sample_y = sample_y[shuffle_index]\n",
    "    \n",
    "    upsample_x_list.append(sample_x)\n",
    "    upsample_y_list.append(sample_y)\n",
    "\n",
    "print(\"up-sampled train dataset:\", sample_x.shape, sample_y.shape)\n",
    "print(\"test dataset:\", test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b1ea4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T01:49:19.256929Z",
     "start_time": "2023-01-21T01:49:16.117191Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "def basicMLP(x_dim, y_dim, n_layers, n_neurons):\n",
    "    mlp_input = Input(shape=(x_dim,), name='dense_input')\n",
    "    \n",
    "    # MLP module\n",
    "    for i in range(n_layers):\n",
    "        if i==0:\n",
    "            dense_output = Dense(n_neurons, name=f\"dense_{i+1}\")(mlp_input)\n",
    "        else: \n",
    "            dense_output = Dense(n_neurons, name=f\"dense_{i+1}\")(dense_output)\n",
    "    mlp_output = Dense(y_dim, name=f\"dense_output\", activation='sigmoid')(dense_output)\n",
    "    \n",
    "    model = Model(mlp_input, mlp_output)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(loss='binary_crossentropy',optimizer = optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9784712e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T01:49:20.017250Z",
     "start_time": "2023-01-21T01:49:19.257896Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def scores(y_real, y_pred, rounding=4):\n",
    "    \n",
    "    accuracy  = 100*np.array(accuracy_score(y_real, y_pred)).round(rounding)\n",
    "    precision = 100*np.array(precision_score(y_real, y_pred, average=None)).round(rounding)[1]\n",
    "    recall    = 100*np.array(recall_score(y_real, y_pred, average=None)).round(rounding)[1]\n",
    "    f1        = 100*np.array(f1_score(y_real, y_pred, average=None)).round(rounding)[1]\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fedc0b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-01-21T01:49:13.752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random, 1 of 100: 5 layers, 292 neurons\n",
      "history is loaded from: ./score/v4_upsampled_MLP_without_window_hpo_1of100.csv\n",
      "random, 2 of 100: 2 layers, 47 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_2of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_2of100.csv\n",
      "random, 3 of 100: 8 layers, 304 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_3of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_3of100.csv\n",
      "random, 4 of 100: 8 layers, 156 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_4of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_4of100.csv\n",
      "random, 5 of 100: 9 layers, 380 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_5of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_5of100.csv\n",
      "random, 6 of 100: 19 layers, 421 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_6of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_6of100.csv\n",
      "random, 7 of 100: 11 layers, 486 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_7of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_7of100.csv\n",
      "random, 8 of 100: 8 layers, 190 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_8of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_8of100.csv\n",
      "random, 9 of 100: 15 layers, 314 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_9of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_9of100.csv\n",
      "random, 10 of 100: 19 layers, 17 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_10of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_10of100.csv\n",
      "random, 11 of 100: 15 layers, 444 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_11of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_11of100.csv\n",
      "random, 12 of 100: 16 layers, 138 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_12of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_12of100.csv\n",
      "random, 13 of 100: 9 layers, 149 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_13of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_13of100.csv\n",
      "random, 14 of 100: 4 layers, 316 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_14of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_14of100.csv\n",
      "random, 15 of 100: 7 layers, 6 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_15of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_15of100.csv\n",
      "random, 16 of 100: 12 layers, 241 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_16of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_16of100.csv\n",
      "random, 17 of 100: 17 layers, 213 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_17of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_17of100.csv\n",
      "random, 18 of 100: 6 layers, 63 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_18of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_18of100.csv\n",
      "random, 19 of 100: 2 layers, 402 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_19of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_19of100.csv\n",
      "random, 20 of 100: 5 layers, 134 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_20of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_20of100.csv\n",
      "random, 21 of 100: 6 layers, 215 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_21of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_21of100.csv\n",
      "random, 22 of 100: 5 layers, 125 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_22of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_22of100.csv\n",
      "random, 23 of 100: 10 layers, 457 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_23of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_23of100.csv\n",
      "random, 24 of 100: 13 layers, 430 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_24of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_24of100.csv\n",
      "random, 25 of 100: 13 layers, 394 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_25of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_25of100.csv\n",
      "random, 26 of 100: 7 layers, 338 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_26of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_26of100.csv\n",
      "random, 27 of 100: 16 layers, 360 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_27of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_27of100.csv\n",
      "random, 28 of 100: 4 layers, 381 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_28of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_28of100.csv\n",
      "random, 29 of 100: 18 layers, 39 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_29of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_29of100.csv\n",
      "random, 30 of 100: 18 layers, 414 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_30of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_30of100.csv\n",
      "random, 31 of 100: 1 layers, 241 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_31of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_31of100.csv\n",
      "random, 32 of 100: 3 layers, 475 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_32of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_32of100.csv\n",
      "random, 33 of 100: 19 layers, 86 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_33of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_33of100.csv\n",
      "random, 34 of 100: 17 layers, 183 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_34of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_34of100.csv\n",
      "random, 35 of 100: 18 layers, 172 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_35of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_35of100.csv\n",
      "random, 36 of 100: 11 layers, 30 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_36of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_36of100.csv\n",
      "random, 37 of 100: 3 layers, 479 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_37of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_37of100.csv\n",
      "random, 38 of 100: 14 layers, 220 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_38of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_38of100.csv\n",
      "random, 39 of 100: 7 layers, 133 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_39of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_39of100.csv\n",
      "random, 40 of 100: 15 layers, 297 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_40of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_40of100.csv\n",
      "random, 41 of 100: 13 layers, 171 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_41of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_41of100.csv\n",
      "random, 42 of 100: 4 layers, 13 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_42of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_42of100.csv\n",
      "random, 43 of 100: 2 layers, 147 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_43of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_43of100.csv\n",
      "random, 44 of 100: 14 layers, 267 neurons\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_44of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_44of100.csv\n",
      "random, 45 of 100: 9 layers, 214 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_45of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_45of100.csv\n",
      "random, 46 of 100: 3 layers, 205 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_46of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_46of100.csv\n",
      "random, 47 of 100: 12 layers, 33 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_47of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_47of100.csv\n",
      "random, 48 of 100: 18 layers, 162 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_48of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_48of100.csv\n",
      "random, 49 of 100: 3 layers, 177 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_49of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_49of100.csv\n",
      "random, 50 of 100: 16 layers, 439 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_50of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_50of100.csv\n",
      "random, 51 of 100: 8 layers, 430 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_51of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_51of100.csv\n",
      "random, 52 of 100: 9 layers, 28 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_52of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_52of100.csv\n",
      "random, 53 of 100: 7 layers, 234 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_53of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_53of100.csv\n",
      "random, 54 of 100: 5 layers, 225 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_54of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_54of100.csv\n",
      "random, 55 of 100: 3 layers, 487 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_55of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_55of100.csv\n",
      "random, 56 of 100: 18 layers, 6 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_56of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_56of100.csv\n",
      "random, 57 of 100: 2 layers, 189 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_57of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_57of100.csv\n",
      "random, 58 of 100: 19 layers, 101 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_58of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_58of100.csv\n",
      "random, 59 of 100: 8 layers, 44 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_59of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_59of100.csv\n",
      "random, 60 of 100: 10 layers, 146 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_60of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_60of100.csv\n",
      "random, 61 of 100: 16 layers, 94 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_61of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_61of100.csv\n",
      "random, 62 of 100: 19 layers, 89 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_62of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_62of100.csv\n",
      "random, 63 of 100: 15 layers, 228 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_63of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_63of100.csv\n",
      "random, 64 of 100: 16 layers, 64 neurons\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_hpo_64of100.h5\n",
      "history is saved to: ./score/v4_upsampled_MLP_without_window_hpo_64of100.csv\n",
      "random, 65 of 100: 14 layers, 148 neurons\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SEOKYOUNG\\AppData\\Local\\Temp\\ipykernel_34496\\782584765.py\", line 45, in <module>\n",
      "    epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 915, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 947, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2454, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1861, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 502, in call\n",
      "    ctx=ctx)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 55, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SEOKYOUNG\\AppData\\Local\\Temp\\ipykernel_34496\\782584765.py\", line 45, in <module>\n",
      "    epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 915, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 947, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2454, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1861, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 502, in call\n",
      "    ctx=ctx)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 55, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SEOKYOUNG\\AppData\\Local\\Temp\\ipykernel_34496\\782584765.py\", line 45, in <module>\n",
      "    epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 915, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 947, in _call\n",
      "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2454, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1861, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 502, in call\n",
      "    ctx=ctx)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 55, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "## hyper-parameter optimization\n",
    "model_type = 'upsampled_MLP_without_window'\n",
    "\n",
    "valid_size = test_size/(1-test_size)\n",
    "patience = 30\n",
    "monitor = 'val_loss'\n",
    "random_state = random_state\n",
    "early_stopping_cb = EarlyStopping(patience=patience, restore_best_weights=True, monitor=monitor)\n",
    "\n",
    "parameter_config = {\n",
    "    \"n_layers\" : range(1,20),\n",
    "    \"n_neurons\" : range(1, 501)\n",
    "}\n",
    "\n",
    "method = \"random\"\n",
    "counts = 100\n",
    "metrics = ['time', 'n_layers', 'n_neurons', 'loss', 'val_loss', 'test_loss', 'accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "train_x = upsample_x_list[0]\n",
    "train_y = upsample_y_list[0]\n",
    "test_x = test_x_list[0]\n",
    "test_y = test_y_list[0]\n",
    "\n",
    "hpo_result = pd.DataFrame([], columns=metrics)\n",
    "for i in range(counts):\n",
    "    random.seed(i+1)\n",
    "    n_layers = random.choice(parameter_config[\"n_layers\"])\n",
    "    n_neurons = random.choice(parameter_config[\"n_neurons\"])\n",
    "    print(f\"random, {i+1} of {counts}: {n_layers} layers, {n_neurons} neurons\")\n",
    "    \n",
    "    model_name = f'{version}_{model_type}_hpo_{i+1}of{counts}'\n",
    "    save_path  = f'./model/{model_name}.h5'\n",
    "    score_path = f\"./score/{model_name}.csv\"\n",
    "    \n",
    "    x_dim = train_x.shape[1]\n",
    "    y_dim = train_y.shape[1]\n",
    "    model = basicMLP(x_dim, y_dim, n_layers, n_neurons)\n",
    "    \n",
    "    if not exists(save_path) or update:\n",
    "        tf.random.set_seed(i+1)\n",
    "        \n",
    "        time_start = time.time()\n",
    "        history = model.fit(train_x, train_y, verbose=0,\n",
    "                            epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n",
    "        time_end = time.time()\n",
    "        time_elapse = round((time_end - time_start)/60, 3)\n",
    "        \n",
    "        model.save_weights(save_path)\n",
    "        print(f\"model is saved to: {save_path}\")\n",
    "        \n",
    "        idx = np.array(history.history[monitor]).argmin()\n",
    "        val_loss = history.history['val_loss'][idx]\n",
    "        loss = history.history['loss'][idx]\n",
    "        test_loss = model.evaluate(test_x, test_y, verbose=0)[0]\n",
    "        prediction = model.predict(test_x, verbose=0)\n",
    "        prediction = prediction.round(0).astype(int)\n",
    "        y_real = test_y\n",
    "        y_pred = prediction\n",
    "        accuracy, precision, recall, f1 = scores(y_real, y_pred)\n",
    "        scores_df = pd.DataFrame([[time_elapse, n_layers, n_neurons, loss, val_loss, test_loss, accuracy, precision, recall, f1]], \n",
    "                                  columns=metrics)\n",
    "\n",
    "        scores_df.to_csv(score_path)\n",
    "        print(f\"history is saved to: {score_path}\")\n",
    "\n",
    "    else:\n",
    "        scores_df = pd.read_csv(score_path, index_col=0, header=0)\n",
    "        print(f\"history is loaded from: {score_path}\")\n",
    "        \n",
    "    hpo_result = pd.concat([hpo_result, scores_df], axis=0)\n",
    "\n",
    "hpo_result = hpo_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d88082fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T17:03:30.964091Z",
     "start_time": "2023-01-21T17:03:30.836431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyperparamerter: index 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "time            6.845\n",
       "n_layers            6\n",
       "n_neurons         215\n",
       "loss         0.663332\n",
       "val_loss     0.660195\n",
       "test_loss    0.639638\n",
       "accuracy         63.3\n",
       "precision        1.78\n",
       "recall          51.92\n",
       "f1               3.44\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.488219</td>\n",
       "      <td>0.668633</td>\n",
       "      <td>0.660753</td>\n",
       "      <td>0.653729</td>\n",
       "      <td>60.687969</td>\n",
       "      <td>1.661719</td>\n",
       "      <td>51.847656</td>\n",
       "      <td>3.219375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.589315</td>\n",
       "      <td>0.025304</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.015569</td>\n",
       "      <td>3.273064</td>\n",
       "      <td>0.048519</td>\n",
       "      <td>3.873572</td>\n",
       "      <td>0.090797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.845000</td>\n",
       "      <td>0.660879</td>\n",
       "      <td>0.659464</td>\n",
       "      <td>0.601813</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>1.560000</td>\n",
       "      <td>41.350000</td>\n",
       "      <td>3.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.766000</td>\n",
       "      <td>0.661477</td>\n",
       "      <td>0.659684</td>\n",
       "      <td>0.643853</td>\n",
       "      <td>59.417500</td>\n",
       "      <td>1.630000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.835000</td>\n",
       "      <td>0.662095</td>\n",
       "      <td>0.659808</td>\n",
       "      <td>0.653765</td>\n",
       "      <td>60.905000</td>\n",
       "      <td>1.670000</td>\n",
       "      <td>51.920000</td>\n",
       "      <td>3.225000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.463750</td>\n",
       "      <td>0.664659</td>\n",
       "      <td>0.660076</td>\n",
       "      <td>0.662754</td>\n",
       "      <td>62.185000</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>53.850000</td>\n",
       "      <td>3.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.273000</td>\n",
       "      <td>0.851449</td>\n",
       "      <td>0.674532</td>\n",
       "      <td>0.704120</td>\n",
       "      <td>68.340000</td>\n",
       "      <td>1.780000</td>\n",
       "      <td>71.150000</td>\n",
       "      <td>3.440000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            time       loss   val_loss  test_loss   accuracy  precision  \\\n",
       "count  64.000000  64.000000  64.000000  64.000000  64.000000  64.000000   \n",
       "mean   14.488219   0.668633   0.660753   0.653729  60.687969   1.661719   \n",
       "std     5.589315   0.025304   0.003013   0.015569   3.273064   0.048519   \n",
       "min     6.845000   0.660879   0.659464   0.601813  43.200000   1.560000   \n",
       "25%     9.766000   0.661477   0.659684   0.643853  59.417500   1.630000   \n",
       "50%    13.835000   0.662095   0.659808   0.653765  60.905000   1.670000   \n",
       "75%    18.463750   0.664659   0.660076   0.662754  62.185000   1.690000   \n",
       "max    29.273000   0.851449   0.674532   0.704120  68.340000   1.780000   \n",
       "\n",
       "          recall         f1  \n",
       "count  64.000000  64.000000  \n",
       "mean   51.847656   3.219375  \n",
       "std     3.873572   0.090797  \n",
       "min    41.350000   3.030000  \n",
       "25%    50.000000   3.157500  \n",
       "50%    51.920000   3.225000  \n",
       "75%    53.850000   3.275000  \n",
       "max    71.150000   3.440000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 841\n"
     ]
    }
   ],
   "source": [
    "# show the HPO result\n",
    "target_metric = 'f1'\n",
    "best_idx = hpo_result[target_metric].argmax()\n",
    "best_parameters = hpo_result.iloc[best_idx]\n",
    "print(f'best hyperparamerter: index {best_idx}')\n",
    "display(best_parameters)\n",
    "\n",
    "display(hpo_result.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5c1b7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-01-21T01:49:13.755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th iteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SEOKYOUNG\\AppData\\Local\\Temp\\ipykernel_34496\\3092089089.py\", line 19, in <module>\n",
      "    epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\engine\\training.py\", line 1456, in fit\n",
      "    _use_cached_eval_dataset=True)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\engine\\training.py\", line 1756, in evaluate\n",
      "    tmp_logs = self.test_function(iterator)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 915, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 954, in _call\n",
      "    results = self._stateful_fn(*args, **kwds)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2454, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1861, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 502, in call\n",
      "    ctx=ctx)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 55, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SEOKYOUNG\\AppData\\Local\\Temp\\ipykernel_34496\\3092089089.py\", line 19, in <module>\n",
      "    epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\engine\\training.py\", line 1456, in fit\n",
      "    _use_cached_eval_dataset=True)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\engine\\training.py\", line 1756, in evaluate\n",
      "    tmp_logs = self.test_function(iterator)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 915, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 954, in _call\n",
      "    results = self._stateful_fn(*args, **kwds)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2454, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1861, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 502, in call\n",
      "    ctx=ctx)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 55, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\SEOKYOUNG\\AppData\\Local\\Temp\\ipykernel_34496\\3092089089.py\", line 19, in <module>\n",
      "    epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\engine\\training.py\", line 1456, in fit\n",
      "    _use_cached_eval_dataset=True)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\engine\\training.py\", line 1756, in evaluate\n",
      "    tmp_logs = self.test_function(iterator)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 915, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 954, in _call\n",
      "    results = self._stateful_fn(*args, **kwds)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 2454, in __call__\n",
      "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1861, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager))\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 502, in call\n",
      "    ctx=ctx)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 55, in quick_execute\n",
      "    inputs, attrs, num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3377, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3474, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1125, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2960, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3186, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3396, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2080, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1368, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1268, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1143, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2077, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"D:\\anaconda3\\envs\\dualattn\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# train the models for cross validation\n",
    "n_layers = best_parameters['n_layers']\n",
    "n_neurons = best_parameters['n_neurons']\n",
    "\n",
    "i=1\n",
    "for train_x, train_y in zip(upsample_x_list, upsample_y_list):\n",
    "    print(f\"{i}th iteration\")\n",
    "    model_name = f'{version}_{model_type}_{n_layers}_{n_neurons}_cv_{i}of{n_splits}'\n",
    "    save_path  = f'./model/{model_name}.h5'\n",
    "    \n",
    "    if not exists(save_path) or update:\n",
    "        x_dim = train_x.shape[1]\n",
    "        y_dim = train_y.shape[1]\n",
    "        model = basicMLP(x_dim, y_dim, n_layers, n_neurons)\n",
    "\n",
    "        if not exists(save_path) or update:\n",
    "            tf.random.set_seed(random_state)\n",
    "            history = model.fit(train_x, train_y, verbose=0,\n",
    "                                epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n",
    "            model.save_weights(save_path)\n",
    "            print(f\"model is saved to: {save_path}\")\n",
    "    else:\n",
    "        print(f\"model already exists at: {save_path}\")\n",
    "    i += 1\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04ff491b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T17:06:39.558880Z",
     "start_time": "2023-01-21T17:06:39.192338Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 842\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = './model/v4_upsampled_MLP_without_window_6_215_cv_1of10.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_34496\\734117590.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbasicMLP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neurons\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[0;32m    531\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[1;32m--> 533\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\dualattn\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = './model/v4_upsampled_MLP_without_window_6_215_cv_1of10.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# get the result of cross validation\n",
    "i=1\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "for test_x, test_y in zip(test_x_list, test_y_list):\n",
    "    model_name = f'{version}_{model_type}_{n_layers}_{n_neurons}_cv_{i}of{n_splits}'\n",
    "    save_path  = f'./model/{model_name}.h5'\n",
    "    \n",
    "    model = basicMLP(x_dim, y_dim, n_layers, n_neurons)\n",
    "    model.load_weights(save_path)\n",
    "    \n",
    "    prediction = model.predict(test_x, verbose=0)\n",
    "    prediction = prediction.round(0).astype(int)\n",
    "\n",
    "    y_real = test_y\n",
    "    y_pred = prediction\n",
    "    \n",
    "    accuracy  = 100*np.array(accuracy_score(y_real, y_pred)).round(4)\n",
    "    precision = 100*np.array(precision_score(y_real, y_pred, average=None)).round(4)[1]\n",
    "    recall    = 100*np.array(recall_score(y_real, y_pred, average=None)).round(4)[1]\n",
    "    f1        = 100*np.array(f1_score(y_real, y_pred, average=None)).round(4)[1]\n",
    "    \n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    \n",
    "accuracies = np.array(accuracy_list)\n",
    "precisions = np.array(precision_list)\n",
    "recalls = np.array(recall_list)\n",
    "f1s = np.array(f1_list)\n",
    "\n",
    "results = pd.DataFrame(np.array([accuracies, precisions, recalls, f1s]).T, columns=['accuracy', 'precision', 'recall', 'f1-score'])\n",
    "results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9a9856",
   "metadata": {},
   "source": [
    "# Case 2: with window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d28b9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T17:06:39.561847Z",
     "start_time": "2023-01-21T17:06:39.561847Z"
    }
   },
   "outputs": [],
   "source": [
    "x_cat = ['SEQ', 'nS/nT', 'nAli', 'nPos', 'phi_psi', 'SS', \n",
    "         'side_-1', 'side_1', 'side_2', 'side_3','side_4', 'side_5']\n",
    "x_cts = ['Proline', 'flexibility']\n",
    "y_label = ['positivity']\n",
    "\n",
    "data_x = pd.get_dummies(ST_dataset[x_cts+x_cat], columns=x_cat)\n",
    "data_y = ST_dataset[y_label]\n",
    "\n",
    "print(data_x.shape)\n",
    "print(data_y.shape)\n",
    "\n",
    "print(\"\\nx columns:\")\n",
    "display(pd.Series(data_x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb456699",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T17:06:39.563842Z",
     "start_time": "2023-01-21T17:06:39.563842Z"
    }
   },
   "outputs": [],
   "source": [
    "### split data into train/test dataset ###\n",
    "split = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "arr_x, arr_y = data_x.values, data_y.values # convert dataframe to nd-array \n",
    "\n",
    "i=1\n",
    "train_idx_list, train_x_list, train_y_list, test_idx_list, test_x_list, test_y_list = [], [], [], [], [], []\n",
    "for train_index, test_index in split.split(arr_x, arr_y):\n",
    "    train_x = arr_x[train_index]\n",
    "    train_y = arr_y[train_index]\n",
    "    test_x = arr_x[test_index]\n",
    "    test_y = arr_y[test_index]\n",
    "    \n",
    "    train_cts = train_x[:,:len(x_cts)]\n",
    "    test_cts  = test_x[:,:len(x_cts)]\n",
    "    \n",
    "    x_min = train_cts.min(axis=0)\n",
    "    x_max = train_cts.max(axis=0)\n",
    "    \n",
    "    train_x[:,:len(x_cts)] = (train_cts-x_min)/(x_max-x_min)\n",
    "    test_x[:,:len(x_cts)] = (test_cts-x_min)/(x_max-x_min)\n",
    "    \n",
    "    print(f\"{i}th iteration\")\n",
    "    print(\"train:\", train_x.shape, train_y.shape, \"check scale:\", train_x.min(), train_x.max())\n",
    "    print(\"test: \", test_x.shape, test_y.shape, \"check scale:\", test_x.min(), test_x.max())\n",
    "    \n",
    "    train_idx_list.append(train_index)\n",
    "    train_x_list.append(train_x)\n",
    "    train_y_list.append(train_y)\n",
    "    \n",
    "    test_idx_list.append(test_index)\n",
    "    test_x_list.append(test_x)\n",
    "    test_y_list.append(test_y)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b54eea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T17:06:39.565837Z",
     "start_time": "2023-01-21T17:06:39.565837Z"
    }
   },
   "outputs": [],
   "source": [
    "## upsampling dataset \n",
    "upsample_x_list, upsample_y_list = [], []\n",
    "for train_x, train_y in zip(train_x_list, train_y_list):\n",
    "    index_pos = np.where(train_y == 1)[0]\n",
    "    index_neg = np.where(train_y == 0)[0]\n",
    "\n",
    "    random.seed(random_state)\n",
    "    up_index = [random.choice(index_pos) for _ in range(len(index_neg))] # get samples from positive sites as much as the number of negative sites\n",
    "\n",
    "    upsample_pos_x = train_x[up_index]\n",
    "    upsample_pos_y = train_y[up_index]\n",
    "    sample_neg_x = train_x[index_neg]\n",
    "    sample_neg_y = train_y[index_neg]\n",
    "\n",
    "    sample_x = np.concatenate([upsample_pos_x, sample_neg_x], axis=0)\n",
    "    sample_y = np.concatenate([upsample_pos_y, sample_neg_y], axis=0)\n",
    "\n",
    "    shuffle_index = np.arange(len(sample_x))\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    sample_x = sample_x[shuffle_index]\n",
    "    sample_y = sample_y[shuffle_index]\n",
    "    \n",
    "    upsample_x_list.append(sample_x)\n",
    "    upsample_y_list.append(sample_y)\n",
    "\n",
    "print(\"up-sampled train dataset:\", sample_x.shape, sample_y.shape)\n",
    "print(\"test dataset:\", test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb39e4b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T17:06:39.567831Z",
     "start_time": "2023-01-21T17:06:39.567831Z"
    }
   },
   "outputs": [],
   "source": [
    "## hyper-parameter optimization\n",
    "model_type = 'upsampled_MLP_original'\n",
    "\n",
    "train_x = upsample_x_list[0]\n",
    "train_y = upsample_y_list[0]\n",
    "test_x = test_x_list[0]\n",
    "test_y = test_y_list[0]\n",
    "\n",
    "hpo_result = pd.DataFrame([], columns=metrics)\n",
    "for i in range(counts):\n",
    "    random.seed(i+1)\n",
    "    n_layers = random.choice(parameter_config[\"n_layers\"])\n",
    "    n_neurons = random.choice(parameter_config[\"n_neurons\"])\n",
    "    print(f\"random, {i+1} of {counts}: {n_layers} layers, {n_neurons} neurons\")\n",
    "    \n",
    "    model_name = f'{version}_{model_type}_hpo_{i+1}of{counts}'\n",
    "    save_path  = f'./model/{model_name}.h5'\n",
    "    score_path = f\"./score/{model_name}.csv\"\n",
    "    \n",
    "    x_dim = train_x.shape[1]\n",
    "    y_dim = train_y.shape[1]\n",
    "\n",
    "    model = basicMLP(x_dim, y_dim, n_layers, n_neurons)\n",
    "    if not exists(save_path) or update:\n",
    "        tf.random.set_seed(i+1)\n",
    "        \n",
    "        time_start = time.time()\n",
    "        history = model.fit(train_x, train_y, verbose=0,\n",
    "                            epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n",
    "        time_end = time.time()\n",
    "        time_elapse = round((time_end - time_start)/60, 3)\n",
    "        \n",
    "        model.save_weights(save_path)\n",
    "        print(f\"model is saved to: {save_path}\")\n",
    "        \n",
    "        idx = np.array(history.history[monitor]).argmin()\n",
    "        val_loss = history.history['val_loss'][idx]\n",
    "        loss = history.history['loss'][idx]\n",
    "        test_loss = model.evaluate(test_x, test_y, verbose=0)[0]\n",
    "        prediction = model.predict(test_x, verbose=0)\n",
    "        prediction = prediction.round(0).astype(int)\n",
    "        y_real = test_y\n",
    "        y_pred = prediction\n",
    "        accuracy, precision, recall, f1 = scores(y_real, y_pred)\n",
    "        scores_df = pd.DataFrame([[time_elapse, n_layers, n_neurons, loss, val_loss, test_loss, accuracy, precision, recall, f1]], \n",
    "                                  columns=metrics)\n",
    "\n",
    "        scores_df.to_csv(score_path)\n",
    "        print(f\"history is saved to: {score_path}\")\n",
    "\n",
    "    else:\n",
    "        scores_df = pd.read_csv(score_path, index_col=0, header=0)\n",
    "        print(f\"history is loaded from: {score_path}\")\n",
    "        \n",
    "    hpo_result = pd.concat([hpo_result, scores_df], axis=0)\n",
    "\n",
    "hpo_result = hpo_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3eba39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T17:06:39.569825Z",
     "start_time": "2023-01-21T17:06:39.569825Z"
    }
   },
   "outputs": [],
   "source": [
    "# show the HPO result\n",
    "target_metric = 'f1'\n",
    "best_idx = hpo_result[target_metric].argmax()\n",
    "best_parameters = hpo_result.iloc[best_idx]\n",
    "print(f'best hyperparamerter: index {best_idx}')\n",
    "display(best_parameters)\n",
    "\n",
    "display(hpo_result.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08489d44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T17:06:39.571819Z",
     "start_time": "2023-01-21T17:06:39.571819Z"
    }
   },
   "outputs": [],
   "source": [
    "# bulid model\n",
    "n_layers = best_parameters['n_layers']\n",
    "n_neurons = best_parameters['n_neurons']\n",
    "\n",
    "i=1\n",
    "for train_x, train_y in zip(upsample_x_list, upsample_y_list):\n",
    "    print(f\"{i}th iteration\")\n",
    "    model_name = f'{version}_{model_type}_{n_layers}_{n_neurons}_cv_{i}of{n_splits}'\n",
    "    save_path  = f'./model/{model_name}.h5'\n",
    "    \n",
    "    if not exists(save_path) or update:\n",
    "        x_dim = train_x.shape[1]\n",
    "        y_dim = train_y.shape[1]\n",
    "        model = basicMLP(x_dim, y_dim, n_layers, n_neurons)\n",
    "\n",
    "        if not exists(save_path) or update:\n",
    "            tf.random.set_seed(random_state)\n",
    "            history = model.fit(train_x, train_y, verbose=0,\n",
    "                                epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n",
    "            model.save_weights(save_path)\n",
    "            print(f\"model is saved to: {save_path}\")\n",
    "    else:\n",
    "        print(f\"model already exists at: {save_path}\")\n",
    "    i += 1\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fe6fe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-21T17:06:39.573814Z",
     "start_time": "2023-01-21T17:06:39.573814Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluate the trained model\n",
    "i=1\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "for test_x, test_y in zip(test_x_list, test_y_list):\n",
    "    model_name = f'{version}_{model_type}_{n_layers}_{n_neurons}_cv_{i}of{n_splits}'\n",
    "    save_path  = f'./model/{model_name}.h5'\n",
    "    \n",
    "    model = basicMLP(x_dim, y_dim, n_layers, n_neurons)\n",
    "    model.load_weights(save_path)\n",
    "    \n",
    "    prediction = model.predict(test_x, verbose=0)\n",
    "    prediction = prediction.round(0).astype(int)\n",
    "\n",
    "    y_real = test_y\n",
    "    y_pred = prediction\n",
    "    \n",
    "    accuracy  = 100*np.array(accuracy_score(y_real, y_pred)).round(4)\n",
    "    precision = 100*np.array(precision_score(y_real, y_pred, average=None)).round(4)[1]\n",
    "    recall    = 100*np.array(recall_score(y_real, y_pred, average=None)).round(4)[1]\n",
    "    f1        = 100*np.array(f1_score(y_real, y_pred, average=None)).round(4)[1]\n",
    "    \n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    \n",
    "accuracies = np.array(accuracy_list)\n",
    "precisions = np.array(precision_list)\n",
    "recalls = np.array(recall_list)\n",
    "f1s = np.array(f1_list)\n",
    "\n",
    "results = pd.DataFrame(np.array([accuracies, precisions, recalls, f1s]).T, columns=['accuracy', 'precision', 'recall', 'f1-score'])\n",
    "results.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dual Attention",
   "language": "python",
   "name": "dualattn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
