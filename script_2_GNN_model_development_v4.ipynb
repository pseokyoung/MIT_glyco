{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b45d8ea4",
   "metadata": {},
   "source": [
    "**What is a graph neural network?**\n",
    "\n",
    "A graph neural network (GNN) is a type of neural network designed to process data represented as a graph. \n",
    "GNNs are used for a variety of tasks such as node classification, link prediction, and graph generation. \n",
    "They are particularly useful for problems that involve analyzing relationships between entities, such as social networks, molecular structures, and transportation networks. GNNs use a combination of neural networks and graph theory to learn features and representations of nodes and edges in a graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c07a1d",
   "metadata": {},
   "source": [
    "**A mechanism of GNNs**\n",
    "\n",
    "Graph Neural Networks (GNNs) are a type of neural network designed to process data represented as a graph. They use a combination of neural networks and graph theory to learn features and representations of nodes and edges in a graph.\n",
    "\n",
    "A graph is a collection of nodes (also called vertices) and edges (also called connections) that connect the nodes. Each node in the graph represents an entity and each edge represents a relationship between two entities.\n",
    "\n",
    "The main mechanism of GNNs is the message passing process. In message passing, the model iteratively updates the representation of each node based on the representations of its neighboring nodes. This process is done by passing messages from each node to its neighboring nodes through the edges that connect them.\n",
    "\n",
    "The message passing process can be divided into two main steps:\n",
    "1. Aggregation: In the aggregation step, the model aggregates the information from the neighboring nodes. This is usually done by taking a weighted sum of the representations of the neighboring nodes, where the weights are learned by the model.\n",
    "1. Update: In the update step, the model updates the representation of the current node based on the aggregated information. This is usually done by applying a neural network to the aggregated information.\n",
    "\n",
    "This process is repeated for a fixed number of iterations or until a stopping criterion is met.\n",
    "One of the key components of GNNs is the use of a trainable function called the \"GNN layer\" which is applied to the updated representation of each node, this function is used to update the representation of each node and can be a neural network like MLP, RNN, CNN. The final representation of each node is used as the output of the GNN.\n",
    "\n",
    "GNNs can be applied to various tasks such as node classification, link prediction, and graph generation. They have been widely used in various fields such as natural language processing, computer vision, bioinformatics, and social networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c9d86b",
   "metadata": {},
   "source": [
    "**Several types of GNNs**\n",
    "\n",
    "There are several types of Graph Neural Networks (GNNs) that have been developed, each with its own strengths and weaknesses. Some of the most common types of GNNs include:\n",
    "\n",
    "1. Graph Convolutional Networks (GCNs): GCNs use a convolutional architecture to process graph data. They are based on the convolutional neural networks (CNNs) used in image processing, but are adapted to work with graph-structured data. GCNs use a local neighborhood aggregation scheme to update the representation of each node.\n",
    "\n",
    "1. Graph Attention Networks (GATs): GATs use an attention mechanism to weight the contributions of neighboring nodes when updating the representation of each node. This allows the model to focus on the most important neighbors for each node.\n",
    "\n",
    "1. Graph Recurrent Networks (GRNs): GRNs use a recurrent architecture to process graph data. They are based on the recurrent neural networks (RNNs) used in sequential data, but are adapted to work with graph-structured data.\n",
    "\n",
    "1. Graph Auto-Encoders (GAEs): GAEs are neural networks that are designed to learn representations of graphs in a low-dimensional space. They consist of two main components: an encoder that maps the graph to a low-dimensional representation, and a decoder that maps the low-dimensional representation back to the original graph.\n",
    "\n",
    "1. Graph Transformer Networks (GTNs): GTNs are based on the transformer architecture, which is widely used in natural language processing. They use self-attention mechanisms to weight the contributions of neighboring nodes when updating the representation of each node.\n",
    "\n",
    "1. Simplifying GNNs: Simplifying GNNs are designed to reduce the complexity of GNNs, making them more efficient and scalable. Some examples of simplifying GNNs include GraphSAGE, FastGCN, and JK-Net.\n",
    "\n",
    "These are some of the most popular types of GNNs, but there are many other variations and combinations that have been proposed in the literature. The choice of GNN architecture will depend on the specific problem and dataset you're working with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcdff43",
   "metadata": {},
   "source": [
    "**Graph Convolutional Networks (GCNs)**\n",
    "\n",
    "Graph Convolutional Networks (GCNs) are one of the most popular types of Graph Neural Networks (GNNs). They were first introduced by Thomas Kipf and Max Welling in 2017 in the paper \"Semi-Supervised Classification with Graph Convolutional Networks\".\n",
    "\n",
    "GCNs are based on the convolutional neural networks (CNNs) used in image processing, but are adapted to work with graph-structured data. They use a local neighborhood aggregation scheme to update the representation of each node and a trainable convolutional kernel to learn the weights.\n",
    "\n",
    "GCNs have been successfully applied to a variety of graph-based tasks such as node classification, link prediction, and graph generation. They have been widely used in various fields such as natural language processing, computer vision, bioinformatics, and social networks.\n",
    "\n",
    "One of the key advantages of GCNs is that they can effectively capture local structural information in the graph, making them well suited for tasks that involve analyzing relationships between entities. They also have a relatively simple architecture and can be trained efficiently on large graphs.\n",
    "\n",
    "Due to their simplicity and good performance, GCNs have become the go-to choice for many researchers working on graph-based problems. It is not the only one but one of the most popular GNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d803dea2",
   "metadata": {},
   "source": [
    "**1. Aggregation steps**\n",
    "\n",
    "In Graph Convolutional Networks (GCNs), the aggregation step is used to combine the information from a node's neighborhood in order to update the node's representation. The aggregation step is typically performed using a weighted sum, where the weights are learned during training.\n",
    "\n",
    "The mathematical formulation of the aggregation step in GCNs can be represented as follows:\n",
    "\n",
    "Given a graph $G = (V, E)$ with n nodes and m edges, and a set of node features $X ∈ R^{nxd}$, where d is the number of features for each node.\n",
    "\n",
    "Let A be the adjacency matrix of the graph, where $A_{i,j} = 1$ if there is an edge between node i and j, and 0 otherwise.\n",
    "\n",
    "Let D be the degree matrix of the graph, where $D_{i,i}$ is the degree of node i.\n",
    "\n",
    "The normalized adjacency matrix is defined as:\n",
    "$\\hat{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$\n",
    "\n",
    "The graph convolution is defined as:\n",
    "$H^{(l+1)} = \\sigma(\\hat{A}H^{(l)}W^{(l)})$\n",
    "\n",
    "where $H^(l)$ is the node representations at the l-th layer, $W^(l)$ is the weight matrix of the l-th layer, and $σ$ is the non-linear activation function.\n",
    "\n",
    "The above equation describes the aggregation step in GCNs, where the representations of the node's neighbors are combined with the node's own representation and the learned weight matrix, in order to update the node's representation.\n",
    "\n",
    "In summary, the aggregation step in GCNs is a mathematical operation that combines the information from a node's neighborhood in order to update the node's representation. It is performed using a weighted sum, where the weights are learned during training, and it is typically performed by multiplying the adjacency matrix by the node feature matrix and a learned weight matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3d5149",
   "metadata": {},
   "source": [
    "**2. Update steps**\n",
    "\n",
    "In Graph Convolutional Networks (GCNs), the update step is used to update the representation of each node in the graph, based on the information gathered from the aggregation step. The update step is typically performed using a linear transformation of the aggregated information, where the transformation is learned during training.\n",
    "\n",
    "The mathematical formulation of the update step in GCNs can be represented as follows:\n",
    "\n",
    "Given the aggregation step, which computes the new node features as:\n",
    "$H^{(l+1)} = \\sigma(\\hat{A}H^{(l)}W^{(l)})$\n",
    "\n",
    "Where $H^{(l)}$ is the node representations at the l-th layer, $W^{(l)}$ is the weight matrix of the l-th layer, $\\hat{A}$ is the normalized adjacency matrix, and $\\sigma$ is the non-linear activation function.\n",
    "\n",
    "The update step can be written as:\n",
    "$H^{(l+1)} = H^{(l+1)} + H^{(l)}$\n",
    "\n",
    "This equation simply adds the new node representations computed by the aggregation step to the current node representations. This allows the model to incorporate both the local structural information from the neighborhood and the node's own features.\n",
    "\n",
    "In summary, the update step of GCN is a mathematical operation that updates the representation of each node in the graph based on the information gathered from the aggregation step. It is performed using a linear transformation of the aggregated information, where the transformation is learned during training, and it is typically performed by adding the new node representations computed by the aggregation step to the current node representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d20e8",
   "metadata": {},
   "source": [
    "**Between Keras and Pytorch, which one is more popular for implementing GNN algorithms?**\n",
    "\n",
    "Both Pytorch and Keras are popular deep learning libraries, and both have support for implementing Graph Neural Networks (GNNs). The choice between the two depends on the specific requirements of your project and your personal preferences.\n",
    "\n",
    "Pytorch is a more low-level library and provides more flexibility in terms of customizing the model's architecture and training process. It also has a large community of researchers and developers who contribute to its development and provide support. Pytorch also has a lot of built-in functions for graph processing and various GNNs architectures, which makes it easy to implement GNNs.\n",
    "\n",
    "Keras, on the other hand, is a higher-level library that provides a simpler and more intuitive interface for building and training models. It is also more user-friendly, making it a popular choice for researchers and practitioners who are new to deep learning. Keras also provides support for GNNs through external libraries such as Keras-GCN and keras-gat, but the support is not as extensive as Pytorch.\n",
    "\n",
    "In practice, both libraries are widely used in research and industry, and both have their own advantages and disadvantages. It ultimately comes down to the specific needs of your project and your own experience and preferences. If you are familiar with Pytorch and you need to implement complex GNNs architectures, Pytorch might be the better choice. But if you are new to deep learning and you prefer a more user-friendly interface, Keras might be the better choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f77d365a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:32:08.823779Z",
     "start_time": "2023-01-17T05:32:08.811875Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as tg\n",
    "import torch_geometric.transforms as T\n",
    "# from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d2b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61c7790",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:32:48.668671Z",
     "start_time": "2023-01-17T05:32:48.221871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project\\MIT_glyco\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from os import getcwd \n",
    "from os.path import exists\n",
    "\n",
    "print(getcwd()) # current working directory\n",
    "\n",
    "version = 'v4'\n",
    "update = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffffd073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:25:25.650042Z",
     "start_time": "2023-01-17T05:25:25.650042Z"
    }
   },
   "outputs": [],
   "source": [
    "load_name = f'{version}_all_sites_group.csv'\n",
    "all_sites = pd.read_csv(load_name)\n",
    "\n",
    "protein_list = list(all_sites.protein.unique())\n",
    "pass_list = [\"P24622_2\", \"Q91YE8_2\"] #these proteins have positive sites which are out of bound\n",
    "\n",
    "for x in pass_list:\n",
    "    protein_list.remove(x) \n",
    "    \n",
    "print(\"total number of proteins:\", len(protein_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9ba7d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:25:25.651042Z",
     "start_time": "2023-01-17T05:25:25.651042Z"
    }
   },
   "outputs": [],
   "source": [
    "load_path = './protein_dataset'\n",
    "for i, name in enumerate(protein_list):\n",
    "    load_name = f\"{load_path}/{version}_dataset_{name}.csv\"\n",
    "    temp = pd.read_csv(load_name, index_col=0)\n",
    "    temp['protein'] = temp.index.name\n",
    "\n",
    "    if i==0:\n",
    "        dataset = temp\n",
    "    else:\n",
    "        dataset = pd.concat([dataset, temp], axis=0)\n",
    "dataset = dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13962f42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:25:25.651042Z",
     "start_time": "2023-01-17T05:25:25.651042Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cbcb02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:25:25.652042Z",
     "start_time": "2023-01-17T05:25:25.652042Z"
    }
   },
   "outputs": [],
   "source": [
    "header = ['#', 'protein']\n",
    "x_cts = ['flexibility', 'Proline']\n",
    "x_cat = ['SEQ', 'nAli', 'nPos', 'nS/nT', 'SS', 'phi_psi', \n",
    "         'side_-1', 'side_1', 'side_2', 'side_3', 'side_4', 'side_5']\n",
    "y = ['positivity']\n",
    "\n",
    "dummies = pd.get_dummies(dataset[x_cat], columns=x_cat)\n",
    "display(np.array(dummies.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c12d42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:25:25.653042Z",
     "start_time": "2023-01-17T05:25:25.653042Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_onehot = pd.concat([dataset[header], dataset[x_cts], dummies, dataset[y]], axis=1)\n",
    "display(np.array(dataset_onehot.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d77e2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:25:25.653721Z",
     "start_time": "2023-01-17T05:25:25.653721Z"
    }
   },
   "outputs": [],
   "source": [
    "### generate GNN dataset###\n",
    "\n",
    "win_size = 10\n",
    "\n",
    "for name in protein_list:\n",
    "    name_list = []\n",
    "    adj_list  = []\n",
    "    feat_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    data = dataset_onehot[dataset_onehot['protein']==name].reset_index(drop=True)\n",
    "    ST_index = np.where((data['SEQ_S']==1) | (data['SEQ_T']==1))[0]\n",
    "    for index in ST_index:\n",
    "        start_index = min(max(index-win_size, 0), len(data))\n",
    "        end_index   = max(min(index+win_size+1, len(data)), 0)\n",
    "        index_len = end_index - start_index\n",
    "        \n",
    "        adj_matrix = np.eye(index_len, k=-1) + np.eye(index_len) + np.eye(index_len, k=1)\n",
    "        feat_matrix = data.iloc[start_index:end_index, 2:-1]\n",
    "        label = data.iloc[[index], [-1]]\n",
    "\n",
    "        name_list.append(name)\n",
    "        adj_list.append(adj_matrix)\n",
    "        feat_list.append(feat_matrix)\n",
    "        label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbbd4ef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:45:53.033895Z",
     "start_time": "2023-01-17T05:45:51.723512Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'spmatrix' from 'scipy.sparse' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdgl\u001b[39;00m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdgl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphConv \n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\glyco\\lib\\site-packages\\dgl\\__init__.py:21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m contrib\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m container\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributed\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m random\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sampling\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\glyco\\lib\\site-packages\\dgl\\distributed\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"DGL distributed module\"\"\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistGraphServer, DistGraph, node_split, edge_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistTensor\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partition_graph, load_partition, load_partition_feats, load_partition_book\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\glyco\\lib\\site-packages\\dgl\\distributed\\dist_graph.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheterograph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DGLHeteroGraph\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m heterograph \u001b[38;5;28;01mas\u001b[39;00m dgl_heterograph\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graph \u001b[38;5;28;01mas\u001b[39;00m dgl_graph\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compact_graphs, sort_csr_by_tag, sort_csc_by_tag\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\glyco\\lib\\site-packages\\dgl\\convert.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mapping\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'spmatrix' from 'scipy.sparse' (unknown location)"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import dgl \n",
    "from dgl.nn import GraphConv \n",
    " \n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "\n",
    "import dgl.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8733d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:25:25.653721Z",
     "start_time": "2023-01-17T05:25:25.653721Z"
    }
   },
   "outputs": [],
   "source": [
    "class GCNModel(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCNModel, self).__init__()\n",
    "\n",
    "        self.gc1 = GCNConv(nfeat, nhid)\n",
    "        self.gc2 = GCNConv(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Model and optimizer\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "#GCNModel 객체 생성\n",
    "model = GCNModel(nfeat=data.x.shape[1],\n",
    "            nhid=20,\n",
    "            nclass=data.y.max().item() + 1,\n",
    "            dropout=0.6)\n",
    "\n",
    "#정확도 함수 정의\n",
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    return correct / len(labels)\n",
    "\n",
    "#최적화 객체 생성\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=0.5, weight_decay=.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b5bc28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:25:25.653721Z",
     "start_time": "2023-01-17T05:25:25.653721Z"
    }
   },
   "outputs": [],
   "source": [
    "#train 함수 정의\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index)\n",
    "    loss_train = F.nll_loss(output[data.train_mask], data.y[data.train_mask])\n",
    "    acc_train = accuracy(output[data.train_mask], data.y[data.train_mask])\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    output = model(data.x, data.edge_index)\n",
    "    loss_val = F.nll_loss(output[data.val_mask], data.y[data.val_mask])\n",
    "    acc_val = accuracy(output[data.val_mask], data.y[data.val_mask])\n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "\n",
    "#epchs 100번 학습\n",
    "for epoch in range(100):\n",
    "    train(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd03cbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:25:25.653721Z",
     "start_time": "2023-01-17T05:25:25.653721Z"
    }
   },
   "outputs": [],
   "source": [
    "#test 함수 정의\n",
    "def test():\n",
    "    model.eval()\n",
    "    output = model(data.x, data.edge_index)\n",
    "    loss_test = F.nll_loss(output[data.test_mask], data.y[data.test_mask])\n",
    "    acc_test = accuracy(output[data.test_mask], data.y[data.test_mask])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e491316",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:25:25.653721Z",
     "start_time": "2023-01-17T05:25:25.653721Z"
    }
   },
   "outputs": [],
   "source": [
    "name = protein_list[0]\n",
    "load_path = './protein_dataset'\n",
    "load_name = f\"{load_path}/{version}_dataset_{name}.csv\"\n",
    "\n",
    "dataset = pd.read_csv(load_name, index_col=0)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be345532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T05:25:25.661336Z",
     "start_time": "2023-01-17T05:25:25.661336Z"
    }
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf, linewidth=np.inf) \n",
    "\n",
    "pro_win_size = 10 # protein window size\n",
    "pro_win_len = pro_win_size*2+1 # protein window length\n",
    "\n",
    "pro_ss = pd.read_csv(f\"./protein_sequence/{pro_name}.csv\", index_col=0)\n",
    "pro_S_T = pro_ss[(pro_ss['SEQ']=='S') | (pro_ss['SEQ']=='T')]\n",
    "adjajecency_matrix = np.eye(window_len,window_len, 1) + np.eye(window_len,window_len, -1)\n",
    "\n",
    "adjajecency_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glyco",
   "language": "python",
   "name": "glyco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
