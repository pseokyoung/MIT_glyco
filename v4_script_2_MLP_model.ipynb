{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceeebd00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:20:38.158076Z",
     "start_time": "2023-01-20T18:20:36.546732Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from os import getcwd \n",
    "from os.path import exists\n",
    "\n",
    "getcwd() # current working directory\n",
    "\n",
    "version = 'v4'\n",
    "update = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92892710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:20:39.403184Z",
     "start_time": "2023-01-20T18:20:38.158076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of proteins:       272\n",
      "total number of samples:        41264\n",
      "total number of positive sites: 521\n",
      "total number of negative sites: 40743\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>SEQ</th>\n",
       "      <th>SS</th>\n",
       "      <th>ASA</th>\n",
       "      <th>Phi</th>\n",
       "      <th>Psi</th>\n",
       "      <th>Theta(i-1=&gt;i+1)</th>\n",
       "      <th>Tau(i-2=&gt;i+2)</th>\n",
       "      <th>HSE_alpha_up</th>\n",
       "      <th>HSE_alpha_down</th>\n",
       "      <th>...</th>\n",
       "      <th>side_3</th>\n",
       "      <th>side_4</th>\n",
       "      <th>side_5</th>\n",
       "      <th>nAli</th>\n",
       "      <th>nPos</th>\n",
       "      <th>nS/nT</th>\n",
       "      <th>Proline</th>\n",
       "      <th>phi_psi</th>\n",
       "      <th>positivity</th>\n",
       "      <th>protein</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>103.3</td>\n",
       "      <td>-102.0</td>\n",
       "      <td>132.1</td>\n",
       "      <td>117.6</td>\n",
       "      <td>-150.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>cycle</td>\n",
       "      <td>small</td>\n",
       "      <td>pro</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>A2ABU4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-87.4</td>\n",
       "      <td>138.5</td>\n",
       "      <td>115.2</td>\n",
       "      <td>-125.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>16.7</td>\n",
       "      <td>...</td>\n",
       "      <td>small</td>\n",
       "      <td>very_small</td>\n",
       "      <td>gly</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>A2ABU4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>56.1</td>\n",
       "      <td>-89.9</td>\n",
       "      <td>142.4</td>\n",
       "      <td>116.8</td>\n",
       "      <td>121.2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>normal</td>\n",
       "      <td>pro</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>A2ABU4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>75.5</td>\n",
       "      <td>-82.7</td>\n",
       "      <td>22.5</td>\n",
       "      <td>104.9</td>\n",
       "      <td>-107.4</td>\n",
       "      <td>5.9</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>very_small</td>\n",
       "      <td>normal</td>\n",
       "      <td>very_small</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>A2ABU4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>78.2</td>\n",
       "      <td>-96.3</td>\n",
       "      <td>112.1</td>\n",
       "      <td>112.0</td>\n",
       "      <td>84.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>13.7</td>\n",
       "      <td>...</td>\n",
       "      <td>very_small</td>\n",
       "      <td>cycle</td>\n",
       "      <td>long</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>A2ABU4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41259</th>\n",
       "      <td>2876</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>76.2</td>\n",
       "      <td>-95.6</td>\n",
       "      <td>138.6</td>\n",
       "      <td>117.8</td>\n",
       "      <td>-135.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>very_small</td>\n",
       "      <td>long</td>\n",
       "      <td>small</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>Q9Y520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41260</th>\n",
       "      <td>2881</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>58.2</td>\n",
       "      <td>-99.5</td>\n",
       "      <td>90.7</td>\n",
       "      <td>111.0</td>\n",
       "      <td>-161.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>...</td>\n",
       "      <td>small</td>\n",
       "      <td>long</td>\n",
       "      <td>pro</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>Q9Y520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41261</th>\n",
       "      <td>2891</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>80.3</td>\n",
       "      <td>-102.2</td>\n",
       "      <td>131.1</td>\n",
       "      <td>116.5</td>\n",
       "      <td>-164.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>...</td>\n",
       "      <td>small</td>\n",
       "      <td>long</td>\n",
       "      <td>small</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>Q9Y520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41262</th>\n",
       "      <td>2894</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>106.7</td>\n",
       "      <td>-91.4</td>\n",
       "      <td>100.3</td>\n",
       "      <td>109.1</td>\n",
       "      <td>-163.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>Q9Y520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41263</th>\n",
       "      <td>2896</td>\n",
       "      <td>S</td>\n",
       "      <td>C</td>\n",
       "      <td>98.4</td>\n",
       "      <td>-91.9</td>\n",
       "      <td>113.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6.2</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>alpha</td>\n",
       "      <td>0</td>\n",
       "      <td>Q9Y520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41264 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          # SEQ SS    ASA    Phi    Psi  Theta(i-1=>i+1)  Tau(i-2=>i+2)  \\\n",
       "0         2   T  C  103.3 -102.0  132.1            117.6         -150.0   \n",
       "1         6   S  C   60.0  -87.4  138.5            115.2         -125.9   \n",
       "2         9   S  C   56.1  -89.9  142.4            116.8          121.2   \n",
       "3        16   S  C   75.5  -82.7   22.5            104.9         -107.4   \n",
       "4        18   T  C   78.2  -96.3  112.1            112.0           84.6   \n",
       "...     ...  .. ..    ...    ...    ...              ...            ...   \n",
       "41259  2876   T  C   76.2  -95.6  138.6            117.8         -135.9   \n",
       "41260  2881   T  C   58.2  -99.5   90.7            111.0         -161.6   \n",
       "41261  2891   T  C   80.3 -102.2  131.1            116.5         -164.4   \n",
       "41262  2894   T  C  106.7  -91.4  100.3            109.1         -163.0   \n",
       "41263  2896   S  C   98.4  -91.9  113.0            110.0          100.4   \n",
       "\n",
       "       HSE_alpha_up  HSE_alpha_down  ...      side_3      side_4      side_5  \\\n",
       "0               3.8            13.9  ...       cycle       small         pro   \n",
       "1               7.8            16.7  ...       small  very_small         gly   \n",
       "2               8.2            13.9  ...      normal         pro      normal   \n",
       "3               5.9            14.2  ...  very_small      normal  very_small   \n",
       "4               5.8            13.7  ...  very_small       cycle        long   \n",
       "...             ...             ...  ...         ...         ...         ...   \n",
       "41259           8.8            13.9  ...  very_small        long       small   \n",
       "41260          11.6            16.2  ...       small        long         pro   \n",
       "41261           7.0            14.3  ...       small        long       small   \n",
       "41262           3.1             9.1  ...        None        None        None   \n",
       "41263           2.1             6.2  ...        None        None        None   \n",
       "\n",
       "       nAli nPos nS/nT Proline phi_psi positivity protein  \n",
       "0         0    0     3       0   alpha          0  A2ABU4  \n",
       "1         2    0     4       1   alpha          0  A2ABU4  \n",
       "2         1    0     5       0   alpha          0  A2ABU4  \n",
       "3         2    0     4       0   other          0  A2ABU4  \n",
       "4         1    0     3       0   alpha          0  A2ABU4  \n",
       "...     ...  ...   ...     ...     ...        ...     ...  \n",
       "41259     2    0     3       0   alpha          0  Q9Y520  \n",
       "41260     2    0     4       0   other          0  Q9Y520  \n",
       "41261     2    1     4       0   alpha          0  Q9Y520  \n",
       "41262     0    0     3       0   alpha          0  Q9Y520  \n",
       "41263     0    1     3       0   alpha          0  Q9Y520  \n",
       "\n",
       "[41264 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_name = \"v4_data_all_sites.csv\"\n",
    "dataset = pd.read_csv(load_name)\n",
    "\n",
    "ST_dataset = dataset[(dataset['SEQ']=='S') | (dataset['SEQ']=='T')].reset_index(drop=True)\n",
    "ST_positive = ST_dataset[ST_dataset['positivity']==1]\n",
    "ST_negative = ST_dataset[ST_dataset['positivity']==0]\n",
    "\n",
    "print(\"total number of proteins:      \", len(ST_dataset.protein.unique()))\n",
    "print(\"total number of samples:       \", len(ST_dataset))\n",
    "print(\"total number of positive sites:\", len(ST_positive))\n",
    "print(\"total number of negative sites:\", len(ST_negative))\n",
    "display(ST_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb592ccc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:20:39.450817Z",
     "start_time": "2023-01-20T18:20:39.405257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41264 entries, 0 to 41263\n",
      "Data columns (total 27 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   #                41264 non-null  int64  \n",
      " 1   SEQ              41264 non-null  object \n",
      " 2   SS               41264 non-null  object \n",
      " 3   ASA              41264 non-null  float64\n",
      " 4   Phi              41264 non-null  float64\n",
      " 5   Psi              41264 non-null  float64\n",
      " 6   Theta(i-1=>i+1)  41264 non-null  float64\n",
      " 7   Tau(i-2=>i+2)    41264 non-null  float64\n",
      " 8   HSE_alpha_up     41264 non-null  float64\n",
      " 9   HSE_alpha_down   41264 non-null  float64\n",
      " 10  P(C)             41264 non-null  float64\n",
      " 11  P(H)             41264 non-null  float64\n",
      " 12  P(E)             41264 non-null  float64\n",
      " 13  flexibility      41264 non-null  float64\n",
      " 14  side_-1          41264 non-null  object \n",
      " 15  side_1           41264 non-null  object \n",
      " 16  side_2           41264 non-null  object \n",
      " 17  side_3           41264 non-null  object \n",
      " 18  side_4           41264 non-null  object \n",
      " 19  side_5           41264 non-null  object \n",
      " 20  nAli             41264 non-null  int64  \n",
      " 21  nPos             41264 non-null  int64  \n",
      " 22  nS/nT            41264 non-null  int64  \n",
      " 23  Proline          41264 non-null  int64  \n",
      " 24  phi_psi          41264 non-null  object \n",
      " 25  positivity       41264 non-null  int64  \n",
      " 26  protein          41264 non-null  object \n",
      "dtypes: float64(11), int64(6), object(10)\n",
      "memory usage: 8.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ST_dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8c5cd",
   "metadata": {},
   "source": [
    "# Case 1: without window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06d7578e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:20:39.478987Z",
     "start_time": "2023-01-20T18:20:39.451840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41264, 16)\n",
      "(41264, 1)\n",
      "\n",
      "x columns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                 ASA\n",
       "1                 Phi\n",
       "2                 Psi\n",
       "3     Theta(i-1=>i+1)\n",
       "4       Tau(i-2=>i+2)\n",
       "5        HSE_alpha_up\n",
       "6      HSE_alpha_down\n",
       "7                P(C)\n",
       "8                P(H)\n",
       "9                P(E)\n",
       "10        flexibility\n",
       "11              SEQ_S\n",
       "12              SEQ_T\n",
       "13               SS_C\n",
       "14               SS_E\n",
       "15               SS_H\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_cat = ['SEQ', 'SS']\n",
    "x_cts = ['ASA', 'Phi', 'Psi', 'Theta(i-1=>i+1)', 'Tau(i-2=>i+2)', 'HSE_alpha_up', 'HSE_alpha_down', \n",
    "         'P(C)', 'P(H)', 'P(E)', 'flexibility']\n",
    "y_label = ['positivity']\n",
    "\n",
    "data_x = pd.get_dummies(ST_dataset[x_cts+x_cat], columns=x_cat)\n",
    "data_y = ST_dataset[y_label]\n",
    "\n",
    "print(data_x.shape)\n",
    "print(data_y.shape)\n",
    "\n",
    "print(\"\\nx columns:\")\n",
    "display(pd.Series(data_x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8abb4e7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:20:41.475658Z",
     "start_time": "2023-01-20T18:20:39.479550Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def stratified_split(data_x, data_y, test_size=0.2, n_splits=1, random_state=1, dtype='arr'):\n",
    "\n",
    "    split = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    train_x, train_y, test_x, test_y  = [], [], [], []\n",
    "    if dtype=='df':\n",
    "        data_x = data_x.values\n",
    "        data_y = data_y.values\n",
    "    \n",
    "    for train_index, test_index in split.split(data_x, data_y):\n",
    "        train_x.append(data_x[train_index])\n",
    "        train_y.append(data_y[train_index])\n",
    "\n",
    "        test_x.append(data_x[test_index])\n",
    "        test_y.append(data_y[test_index])\n",
    "        \n",
    "    print(\"train/test dataset\")\n",
    "    print(\"train:\", train_x[0].shape, train_y[0].shape)\n",
    "    print(\"test:\", test_x[0].shape, test_y[0].shape)\n",
    "    \n",
    "    if n_splits == 1:\n",
    "        return train_x[0],train_y[0], test_x[0], test_y[0]\n",
    "    else:\n",
    "        return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1df0358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:20:41.788754Z",
     "start_time": "2023-01-20T18:20:41.475658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.012024048096192367 1.124248496993988\n",
      "2th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: 0.0 1.0173697270471465\n",
      "3th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.01669449081803005 1.0068027210884352\n",
      "4th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.010695187165775383 1.0\n",
      "5th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.004077471967380227 1.0\n",
      "6th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: 0.0 1.1227722772277227\n",
      "7th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.01839464882943134 1.0068027210884352\n",
      "8th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.01669449081803005 1.0765027322404372\n",
      "9th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.001959137979289081 1.0134680134680134\n",
      "10th iteration\n",
      "train: (33011, 16) (33011, 1) check scale: 0.0 1.0\n",
      "test:  (8253, 16) (8253, 1) check scale: -0.01669449081803005 1.0\n"
     ]
    }
   ],
   "source": [
    "### split data into train/test dataset ###\n",
    "test_size = 0.2\n",
    "n_splits = 10\n",
    "random_state = 1\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n",
    "arr_x, arr_y = data_x.values, data_y.values # convert dataframe to nd-array \n",
    "\n",
    "i=1\n",
    "train_idx_list, train_x_list, train_y_list, test_idx_list, test_x_list, test_y_list = [], [], [], [], [], []\n",
    "for train_index, test_index in split.split(arr_x, arr_y):\n",
    "    train_x = arr_x[train_index]\n",
    "    train_y = arr_y[train_index]\n",
    "    test_x = arr_x[test_index]\n",
    "    test_y = arr_y[test_index]\n",
    "    \n",
    "    train_cts = train_x[:,:len(x_cts)]\n",
    "    test_cts  = test_x[:,:len(x_cts)]\n",
    "    \n",
    "    x_min = train_cts.min(axis=0)\n",
    "    x_max = train_cts.max(axis=0)\n",
    "    \n",
    "    train_x[:,:len(x_cts)] = (train_cts-x_min)/(x_max-x_min)\n",
    "    test_x[:,:len(x_cts)] = (test_cts-x_min)/(x_max-x_min)\n",
    "    \n",
    "    print(f\"{i}th iteration\")\n",
    "    print(\"train:\", train_x.shape, train_y.shape, \"check scale:\", train_x.min(), train_x.max())\n",
    "    print(\"test: \", test_x.shape, test_y.shape, \"check scale:\", test_x.min(), test_x.max())\n",
    "    \n",
    "    train_idx_list.append(train_index)\n",
    "    train_x_list.append(train_x)\n",
    "    train_y_list.append(train_y)\n",
    "    \n",
    "    test_idx_list.append(test_index)\n",
    "    test_x_list.append(test_x)\n",
    "    test_y_list.append(test_y)\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d731b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:20:47.233896Z",
     "start_time": "2023-01-20T18:20:47.014283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up-sampled train dataset: (65188, 16) (65188, 1)\n",
      "test dataset: (8253, 16) (8253, 1)\n"
     ]
    }
   ],
   "source": [
    "## upsampling dataset \n",
    "import random\n",
    "random_state = random_state\n",
    "\n",
    "upsample_x_list, upsample_y_list = [], []\n",
    "for train_x, train_y in zip(train_x_list, train_y_list):\n",
    "    index_pos = np.where(train_y == 1)[0]\n",
    "    index_neg = np.where(train_y == 0)[0]\n",
    "\n",
    "    random.seed(random_state)\n",
    "    up_index = [random.choice(index_pos) for _ in range(len(index_neg))] # get samples from positive sites as much as the number of negative sites\n",
    "\n",
    "    upsample_pos_x = train_x[up_index]\n",
    "    upsample_pos_y = train_y[up_index]\n",
    "    sample_neg_x = train_x[index_neg]\n",
    "    sample_neg_y = train_y[index_neg]\n",
    "\n",
    "    sample_x = np.concatenate([upsample_pos_x, sample_neg_x], axis=0)\n",
    "    sample_y = np.concatenate([upsample_pos_y, sample_neg_y], axis=0)\n",
    "\n",
    "    shuffle_index = np.arange(len(sample_x))\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(shuffle_index)\n",
    "    sample_x = sample_x[shuffle_index]\n",
    "    sample_y = sample_y[shuffle_index]\n",
    "    \n",
    "    upsample_x_list.append(sample_x)\n",
    "    upsample_y_list.append(sample_y)\n",
    "\n",
    "print(\"up-sampled train dataset:\", sample_x.shape, sample_y.shape)\n",
    "print(\"test dataset:\", test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b1ea4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:20:56.004456Z",
     "start_time": "2023-01-20T18:20:47.770758Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "def basicMLP(x_dim, y_dim, n_layers, n_neurons):\n",
    "    mlp_input = Input(shape=(x_dim,), name='dense_input')\n",
    "    \n",
    "    # MLP module\n",
    "    for i in range(n_layers):\n",
    "        if i==0:\n",
    "            dense_output = Dense(n_neurons, name=f\"dense_{i+1}\")(mlp_input)\n",
    "        else: \n",
    "            dense_output = Dense(n_neurons, name=f\"dense_{i+1}\")(dense_output)\n",
    "    mlp_output = Dense(y_dim, name=f\"dense_output\", activation='sigmoid')(dense_output)\n",
    "    \n",
    "    model = Model(mlp_input, mlp_output)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001, beta_1=0.9, beta_2=0.999)\n",
    "    model.compile(loss='binary_crossentropy',optimizer = optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9784712e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:20:57.207965Z",
     "start_time": "2023-01-20T18:20:56.004456Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def scores(y_real, y_pred, rounding=4):\n",
    "    \n",
    "    accuracy  = 100*np.array(accuracy_score(y_real, y_pred)).round(rounding)\n",
    "    precision = 100*np.array(precision_score(y_real, y_pred, average=None)).round(rounding)[1]\n",
    "    recall    = 100*np.array(recall_score(y_real, y_pred, average=None)).round(rounding)[1]\n",
    "    f1        = 100*np.array(f1_score(y_real, y_pred, average=None)).round(rounding)[1]\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5fedc0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:26:21.867289Z",
     "start_time": "2023-01-20T18:26:21.829773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random, 1 of 5: 5 layers, 292 neurons\n",
      "history is loaded from: ./score/v4_upsampled_MLP_without_window_hpo_1of5.csv\n",
      "random, 2 of 5: 2 layers, 47 neurons\n",
      "history is loaded from: ./score/v4_upsampled_MLP_without_window_hpo_2of5.csv\n",
      "random, 3 of 5: 8 layers, 304 neurons\n",
      "history is loaded from: ./score/v4_upsampled_MLP_without_window_hpo_3of5.csv\n",
      "random, 4 of 5: 8 layers, 156 neurons\n",
      "history is loaded from: ./score/v4_upsampled_MLP_without_window_hpo_4of5.csv\n",
      "random, 5 of 5: 9 layers, 380 neurons\n",
      "history is loaded from: ./score/v4_upsampled_MLP_without_window_hpo_5of5.csv\n"
     ]
    }
   ],
   "source": [
    "## hyper-parameter optimization\n",
    "model_type = 'upsampled_MLP_without_window'\n",
    "\n",
    "valid_size = test_size/(1-test_size)\n",
    "patience = 30\n",
    "monitor = 'val_loss'\n",
    "random_state = random_state\n",
    "early_stopping_cb = EarlyStopping(patience=patience, restore_best_weights=True, monitor=monitor)\n",
    "\n",
    "parameter_config = {\n",
    "    \"n_layers\" : range(1,20),\n",
    "    \"n_neurons\" : range(1, 501)\n",
    "}\n",
    "\n",
    "method = \"random\"\n",
    "counts = 100\n",
    "metrics = ['time', 'n_layers', 'n_neurons', 'loss', 'val_loss', 'test_loss', 'accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "train_x = upsample_x_list[0]\n",
    "train_y = upsample_y_list[0]\n",
    "test_x = test_x_list[0]\n",
    "test_y = test_y_list[0]\n",
    "\n",
    "hpo_result = pd.DataFrame([], columns=metrics)\n",
    "for i in range(counts):\n",
    "    random.seed(i+1)\n",
    "    n_layers = random.choice(parameter_config[\"n_layers\"])\n",
    "    n_neurons = random.choice(parameter_config[\"n_neurons\"])\n",
    "    print(f\"random, {i+1} of {counts}: {n_layers} layers, {n_neurons} neurons\")\n",
    "    \n",
    "    model_name = f'{version}_{model_type}_hpo_{i+1}of{counts}'\n",
    "    save_path  = f'./model/{model_name}.h5'\n",
    "    score_path = f\"./score/{model_name}.csv\"\n",
    "    \n",
    "    x_dim = train_x.shape[1]\n",
    "    y_dim = train_y.shape[1]\n",
    "\n",
    "    if not exists(save_path) or update:\n",
    "        tf.random.set_seed(i+1)\n",
    "        \n",
    "        time_start = time.time()\n",
    "        history = model.fit(train_x, train_y, verbose=2,\n",
    "                            epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n",
    "        time_end = time.time()\n",
    "        time_elapse = round((time_end - time_start)/60, 3)\n",
    "        \n",
    "        model.save_weights(save_path)\n",
    "        print(f\"model is saved to: {save_path}\")\n",
    "        \n",
    "        idx = np.array(history.history[monitor]).argmin()\n",
    "        val_loss = history.history['val_loss'][idx]\n",
    "        loss = history.history['loss'][idx]\n",
    "        test_loss = model.evaluate(test_x, test_y, verbose=0)[0]\n",
    "        prediction = model.predict(test_x, verbose=0)\n",
    "        prediction = prediction.round(0).astype(int)\n",
    "        y_real = test_y\n",
    "        y_pred = prediction\n",
    "        accuracy, precision, recall, f1 = scores(y_real, y_pred)\n",
    "        scores_df = pd.DataFrame([[time_elapse, n_layers, n_neurons, loss, val_loss, test_loss, accuracy, precision, recall, f1]], \n",
    "                                  columns=metrics)\n",
    "\n",
    "        scores_df.to_csv(score_path)\n",
    "        print(f\"history is saved to: {score_path}\")\n",
    "\n",
    "    else:\n",
    "        scores_df = pd.read_csv(score_path, index_col=0, header=0)\n",
    "        print(f\"history is loaded from: {score_path}\")\n",
    "        \n",
    "    hpo_result = pd.concat([hpo_result, scores_df], axis=0)\n",
    "\n",
    "hpo_result = hpo_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d88082fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-20T18:30:29.364099Z",
     "start_time": "2023-01-20T18:30:29.337210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyperparamerter: index 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "time            1.452\n",
       "n_layers            9\n",
       "n_neurons         380\n",
       "loss         0.660999\n",
       "val_loss     0.659564\n",
       "test_loss    0.644467\n",
       "accuracy         62.7\n",
       "precision        1.75\n",
       "recall          51.92\n",
       "f1               3.39\n",
       "Name: 4, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.0000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.7838</td>\n",
       "      <td>0.660957</td>\n",
       "      <td>0.659546</td>\n",
       "      <td>0.656381</td>\n",
       "      <td>60.580000</td>\n",
       "      <td>1.694000</td>\n",
       "      <td>53.076000</td>\n",
       "      <td>3.284000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.8524</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.009054</td>\n",
       "      <td>1.584345</td>\n",
       "      <td>0.047223</td>\n",
       "      <td>1.256674</td>\n",
       "      <td>0.086197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0760</td>\n",
       "      <td>0.660838</td>\n",
       "      <td>0.659479</td>\n",
       "      <td>0.644467</td>\n",
       "      <td>59.010000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>51.920000</td>\n",
       "      <td>3.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.1380</td>\n",
       "      <td>0.660932</td>\n",
       "      <td>0.659504</td>\n",
       "      <td>0.649613</td>\n",
       "      <td>59.280000</td>\n",
       "      <td>1.690000</td>\n",
       "      <td>51.920000</td>\n",
       "      <td>3.280000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.4520</td>\n",
       "      <td>0.660958</td>\n",
       "      <td>0.659564</td>\n",
       "      <td>0.658674</td>\n",
       "      <td>60.210000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>52.880000</td>\n",
       "      <td>3.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.1480</td>\n",
       "      <td>0.660999</td>\n",
       "      <td>0.659586</td>\n",
       "      <td>0.664068</td>\n",
       "      <td>61.700000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>53.850000</td>\n",
       "      <td>3.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.1050</td>\n",
       "      <td>0.661057</td>\n",
       "      <td>0.659599</td>\n",
       "      <td>0.665086</td>\n",
       "      <td>62.700000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>54.810000</td>\n",
       "      <td>3.390000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time      loss  val_loss  test_loss   accuracy  precision     recall  \\\n",
       "count  5.0000  5.000000  5.000000   5.000000   5.000000   5.000000   5.000000   \n",
       "mean   1.7838  0.660957  0.659546   0.656381  60.580000   1.694000  53.076000   \n",
       "std    0.8524  0.000081  0.000053   0.009054   1.584345   0.047223   1.256674   \n",
       "min    1.0760  0.660838  0.659479   0.644467  59.010000   1.620000  51.920000   \n",
       "25%    1.1380  0.660932  0.659504   0.649613  59.280000   1.690000  51.920000   \n",
       "50%    1.4520  0.660958  0.659564   0.658674  60.210000   1.700000  52.880000   \n",
       "75%    2.1480  0.660999  0.659586   0.664068  61.700000   1.710000  53.850000   \n",
       "max    3.1050  0.661057  0.659599   0.665086  62.700000   1.750000  54.810000   \n",
       "\n",
       "             f1  \n",
       "count  5.000000  \n",
       "mean   3.284000  \n",
       "std    0.086197  \n",
       "min    3.150000  \n",
       "25%    3.280000  \n",
       "50%    3.300000  \n",
       "75%    3.300000  \n",
       "max    3.390000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the HPO result\n",
    "target_metric = 'f1'\n",
    "best_idx = hpo_result[target_metric].argmax()\n",
    "best_parameters = hpo_result.iloc[best_idx]\n",
    "print(f'best hyperparamerter: index {best_idx}')\n",
    "display(best_parameters)\n",
    "\n",
    "display(hpo_result.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "44c5c1b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T23:15:35.329643Z",
     "start_time": "2023-01-19T22:50:24.243664Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th iteration\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_3_100_cv_1of10.h5\n",
      "2th iteration\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_3_100_cv_2of10.h5\n",
      "3th iteration\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_3_100_cv_3of10.h5\n",
      "4th iteration\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_3_100_cv_4of10.h5\n",
      "5th iteration\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_3_100_cv_5of10.h5\n",
      "6th iteration\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_3_100_cv_6of10.h5\n",
      "7th iteration\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_3_100_cv_7of10.h5\n",
      "8th iteration\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_3_100_cv_8of10.h5\n",
      "9th iteration\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_3_100_cv_9of10.h5\n",
      "10th iteration\n",
      "model is saved to: ./model/v4_upsampled_MLP_without_window_3_100_cv_10of10.h5\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_input (InputLayer)    [(None, 16)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               1700      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_output (Dense)        (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,001\n",
      "Trainable params: 22,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bulid model\n",
    "n_layers = best_parameters['n_layers']\n",
    "n_neurons = best_parameters['n_neurons']\n",
    "\n",
    "i=1\n",
    "for train_x, train_y in zip(upsample_x_list, upsample_y_list):\n",
    "    print(f\"{i}th iteration\")\n",
    "    model_name = f'{version}_{model_type}_{n_layers}_{n_neurons}_cv_{i}of{n_splits}'\n",
    "    save_path  = f'./model/{model_name}.h5'\n",
    "    \n",
    "    x_dim = train_x.shape[1]\n",
    "    y_dim = train_y.shape[1]\n",
    "    model = basicMLP(x_dim, y_dim, n_layers, n_neurons)\n",
    "    \n",
    "    if not exists(save_path) or update:\n",
    "        tf.random.set_seed(random_state)\n",
    "        history = model.fit(train_x, train_y, verbose=0,\n",
    "                            epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n",
    "        model.save_weights(save_path)\n",
    "        print(f\"model is saved to: {save_path}\")\n",
    "        \n",
    "    i += 1\n",
    "display(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "04ff491b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T23:49:03.444703Z",
     "start_time": "2023-01-19T23:49:01.044595Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>59.403000</td>\n",
       "      <td>1.831000</td>\n",
       "      <td>59.232000</td>\n",
       "      <td>3.54800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.337037</td>\n",
       "      <td>0.131356</td>\n",
       "      <td>4.033889</td>\n",
       "      <td>0.25516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>57.620000</td>\n",
       "      <td>1.680000</td>\n",
       "      <td>53.850000</td>\n",
       "      <td>3.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.360000</td>\n",
       "      <td>1.712500</td>\n",
       "      <td>56.970000</td>\n",
       "      <td>3.31500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>59.465000</td>\n",
       "      <td>1.825000</td>\n",
       "      <td>58.655000</td>\n",
       "      <td>3.54000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>59.885000</td>\n",
       "      <td>1.907500</td>\n",
       "      <td>60.340000</td>\n",
       "      <td>3.69500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>62.200000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>68.270000</td>\n",
       "      <td>4.01000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  precision     recall  f1-score\n",
       "count  10.000000  10.000000  10.000000  10.00000\n",
       "mean   59.403000   1.831000  59.232000   3.54800\n",
       "std     1.337037   0.131356   4.033889   0.25516\n",
       "min    57.620000   1.680000  53.850000   3.25000\n",
       "25%    58.360000   1.712500  56.970000   3.31500\n",
       "50%    59.465000   1.825000  58.655000   3.54000\n",
       "75%    59.885000   1.907500  60.340000   3.69500\n",
       "max    62.200000   2.070000  68.270000   4.01000"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the trained model\n",
    "i=1\n",
    "accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n",
    "for test_x, test_y in zip(test_x_list, test_y_list):\n",
    "    model_name = f'{version}_{model_type}_{n_layers}_{n_neurons}_cv_{i}of{n_splits}'\n",
    "    save_path  = f'./model/{model_name}.h5'\n",
    "    \n",
    "    model = basicMLP(x_dim, y_dim, n_layers, n_neurons)\n",
    "    model.load_weights(save_path)\n",
    "    \n",
    "    prediction = model.predict(test_x, verbose=0)\n",
    "    prediction = prediction.round(0).astype(int)\n",
    "\n",
    "    y_real = test_y\n",
    "    y_pred = prediction\n",
    "    \n",
    "    accuracy  = 100*np.array(accuracy_score(y_real, y_pred)).round(4)\n",
    "    precision = 100*np.array(precision_score(y_real, y_pred, average=None)).round(4)[1]\n",
    "    recall    = 100*np.array(recall_score(y_real, y_pred, average=None)).round(4)[1]\n",
    "    f1        = 100*np.array(f1_score(y_real, y_pred, average=None)).round(4)[1]\n",
    "    \n",
    "    accuracy_list.append(accuracy)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    \n",
    "accuracies = np.array(accuracy_list)\n",
    "precisions = np.array(precision_list)\n",
    "recalls = np.array(recall_list)\n",
    "f1s = np.array(f1_list)\n",
    "\n",
    "results = pd.DataFrame(np.array([accuracies, precisions, recalls, f1s]).T, columns=['accuracy', 'precision', 'recall', 'f1-score'])\n",
    "results.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python 3.9",
   "language": "python",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
