{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61c7790",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T00:14:36.774224Z",
     "start_time": "2023-01-19T00:14:35.451311Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\project\\MIT_glyco\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "from os import getcwd \n",
    "from os.path import exists\n",
    "\n",
    "print(getcwd()) # current working directory\n",
    "\n",
    "version = 'v4'\n",
    "update = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffffd073",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T00:16:07.010618Z",
     "start_time": "2023-01-19T00:16:06.380639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of proteins: 273\n"
     ]
    }
   ],
   "source": [
    "load_name = f'{version}_positive_sites.csv'\n",
    "all_sites = pd.read_csv(load_name)\n",
    "\n",
    "protein_list = list(all_sites.protein.unique())\n",
    "pass_list = [\"P24622_2\", \"Q91YE8_2\"] #these proteins have positive sites which are out of bound\n",
    "\n",
    "for x in pass_list:\n",
    "    protein_list.remove(x) \n",
    "    \n",
    "print(\"total number of proteins:\", len(protein_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca9ba7d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T00:25:53.411544Z",
     "start_time": "2023-01-19T00:25:46.717806Z"
    }
   },
   "outputs": [],
   "source": [
    "load_path = './protein_dataset'\n",
    "for i, name in enumerate(protein_list):\n",
    "    load_name = f\"{load_path}/{version}_dataset_{name}.csv\"\n",
    "    temp = pd.read_csv(load_name, index_col=0)\n",
    "    temp['protein'] = temp.index.name\n",
    "\n",
    "    if i==0:\n",
    "        dataset = temp\n",
    "    else:\n",
    "        dataset = pd.concat([dataset, temp], axis=0)\n",
    "dataset = dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13962f42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T00:25:55.912969Z",
     "start_time": "2023-01-19T00:25:55.626474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 258653 entries, 0 to 258652\n",
      "Data columns (total 27 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   #                258653 non-null  int64  \n",
      " 1   SEQ              258653 non-null  object \n",
      " 2   SS               258653 non-null  object \n",
      " 3   ASA              258653 non-null  float64\n",
      " 4   Phi              258653 non-null  float64\n",
      " 5   Psi              258653 non-null  float64\n",
      " 6   Theta(i-1=>i+1)  258653 non-null  float64\n",
      " 7   Tau(i-2=>i+2)    258653 non-null  float64\n",
      " 8   HSE_alpha_up     258653 non-null  float64\n",
      " 9   HSE_alpha_down   258653 non-null  float64\n",
      " 10  P(C)             258653 non-null  float64\n",
      " 11  P(H)             258653 non-null  float64\n",
      " 12  P(E)             258653 non-null  float64\n",
      " 13  flexibility      258051 non-null  float64\n",
      " 14  side_-1          258653 non-null  object \n",
      " 15  side_1           258653 non-null  object \n",
      " 16  side_2           258653 non-null  object \n",
      " 17  side_3           258653 non-null  object \n",
      " 18  side_4           258653 non-null  object \n",
      " 19  side_5           258653 non-null  object \n",
      " 20  nAli             258653 non-null  int64  \n",
      " 21  nPos             258653 non-null  int64  \n",
      " 22  nS/nT            258653 non-null  int64  \n",
      " 23  Proline          258653 non-null  int64  \n",
      " 24  phi_psi          258653 non-null  object \n",
      " 25  positivity       258653 non-null  int64  \n",
      " 26  protein          258653 non-null  object \n",
      "dtypes: float64(11), int64(6), object(10)\n",
      "memory usage: 53.3+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3cbcb02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T00:25:57.770915Z",
     "start_time": "2023-01-19T00:25:57.566477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SEQ_A', 'SEQ_C', 'SEQ_D', 'SEQ_E', 'SEQ_F', 'SEQ_G', 'SEQ_H',\n",
       "       'SEQ_I', 'SEQ_K', 'SEQ_L', 'SEQ_M', 'SEQ_N', 'SEQ_P', 'SEQ_Q',\n",
       "       'SEQ_R', 'SEQ_S', 'SEQ_T', 'SEQ_V', 'SEQ_W', 'SEQ_Y', 'nAli_0',\n",
       "       'nAli_1', 'nAli_2', 'nAli_3', 'nPos_0', 'nPos_1', 'nPos_2',\n",
       "       'nPos_3', 'nS/nT_0', 'nS/nT_1', 'nS/nT_2', 'nS/nT_3', 'nS/nT_4',\n",
       "       'nS/nT_5', 'nS/nT_6', 'nS/nT_7', 'nS/nT_8', 'nS/nT_9', 'nS/nT_10',\n",
       "       'nS/nT_11', 'nS/nT_12', 'nS/nT_13', 'nS/nT_14', 'nS/nT_15',\n",
       "       'nS/nT_16', 'nS/nT_17', 'nS/nT_18', 'nS/nT_19', 'nS/nT_20',\n",
       "       'nS/nT_21', 'SS_C', 'SS_E', 'SS_H', 'phi_psi_alpha',\n",
       "       'phi_psi_beta', 'phi_psi_other', 'side_-1_None', 'side_-1_cycle',\n",
       "       'side_-1_gly', 'side_-1_long', 'side_-1_normal', 'side_-1_pro',\n",
       "       'side_-1_small', 'side_-1_very_small', 'side_1_None',\n",
       "       'side_1_cycle', 'side_1_gly', 'side_1_long', 'side_1_normal',\n",
       "       'side_1_pro', 'side_1_small', 'side_1_very_small', 'side_2_None',\n",
       "       'side_2_cycle', 'side_2_gly', 'side_2_long', 'side_2_normal',\n",
       "       'side_2_pro', 'side_2_small', 'side_2_very_small', 'side_3_None',\n",
       "       'side_3_cycle', 'side_3_gly', 'side_3_long', 'side_3_normal',\n",
       "       'side_3_pro', 'side_3_small', 'side_3_very_small', 'side_4_None',\n",
       "       'side_4_cycle', 'side_4_gly', 'side_4_long', 'side_4_normal',\n",
       "       'side_4_pro', 'side_4_small', 'side_4_very_small', 'side_5_None',\n",
       "       'side_5_cycle', 'side_5_gly', 'side_5_long', 'side_5_normal',\n",
       "       'side_5_pro', 'side_5_small', 'side_5_very_small', 'positivity_0',\n",
       "       'positivity_1'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "header = ['#', 'protein']\n",
    "x_cts = ['flexibility', 'Proline']\n",
    "x_cat = ['SEQ', 'nAli', 'nPos', 'nS/nT', 'SS', 'phi_psi', \n",
    "         'side_-1', 'side_1', 'side_2', 'side_3', 'side_4', 'side_5']\n",
    "y = ['positivity']\n",
    "\n",
    "dummies = pd.get_dummies(dataset[x_cat+y], columns=x_cat+y)\n",
    "display(np.array(dummies.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1c12d42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T00:25:59.050714Z",
     "start_time": "2023-01-19T00:25:59.026114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['#', 'protein', 'flexibility', 'Proline', 'SEQ_A', 'SEQ_C',\n",
       "       'SEQ_D', 'SEQ_E', 'SEQ_F', 'SEQ_G', 'SEQ_H', 'SEQ_I', 'SEQ_K',\n",
       "       'SEQ_L', 'SEQ_M', 'SEQ_N', 'SEQ_P', 'SEQ_Q', 'SEQ_R', 'SEQ_S',\n",
       "       'SEQ_T', 'SEQ_V', 'SEQ_W', 'SEQ_Y', 'nAli_0', 'nAli_1', 'nAli_2',\n",
       "       'nAli_3', 'nPos_0', 'nPos_1', 'nPos_2', 'nPos_3', 'nS/nT_0',\n",
       "       'nS/nT_1', 'nS/nT_2', 'nS/nT_3', 'nS/nT_4', 'nS/nT_5', 'nS/nT_6',\n",
       "       'nS/nT_7', 'nS/nT_8', 'nS/nT_9', 'nS/nT_10', 'nS/nT_11',\n",
       "       'nS/nT_12', 'nS/nT_13', 'nS/nT_14', 'nS/nT_15', 'nS/nT_16',\n",
       "       'nS/nT_17', 'nS/nT_18', 'nS/nT_19', 'nS/nT_20', 'nS/nT_21', 'SS_C',\n",
       "       'SS_E', 'SS_H', 'phi_psi_alpha', 'phi_psi_beta', 'phi_psi_other',\n",
       "       'side_-1_None', 'side_-1_cycle', 'side_-1_gly', 'side_-1_long',\n",
       "       'side_-1_normal', 'side_-1_pro', 'side_-1_small',\n",
       "       'side_-1_very_small', 'side_1_None', 'side_1_cycle', 'side_1_gly',\n",
       "       'side_1_long', 'side_1_normal', 'side_1_pro', 'side_1_small',\n",
       "       'side_1_very_small', 'side_2_None', 'side_2_cycle', 'side_2_gly',\n",
       "       'side_2_long', 'side_2_normal', 'side_2_pro', 'side_2_small',\n",
       "       'side_2_very_small', 'side_3_None', 'side_3_cycle', 'side_3_gly',\n",
       "       'side_3_long', 'side_3_normal', 'side_3_pro', 'side_3_small',\n",
       "       'side_3_very_small', 'side_4_None', 'side_4_cycle', 'side_4_gly',\n",
       "       'side_4_long', 'side_4_normal', 'side_4_pro', 'side_4_small',\n",
       "       'side_4_very_small', 'side_5_None', 'side_5_cycle', 'side_5_gly',\n",
       "       'side_5_long', 'side_5_normal', 'side_5_pro', 'side_5_small',\n",
       "       'side_5_very_small', 'positivity_0', 'positivity_1'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_onehot = pd.concat([dataset[header], dataset[x_cts], dummies], axis=1)\n",
    "display(np.array(dataset_onehot.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86d77e2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T00:26:33.773990Z",
     "start_time": "2023-01-19T00:26:33.753991Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_gnn_dataset(protein_list, dataset_onehot):\n",
    "    \"\"\"\n",
    "    Generate graph-structured data of protein sequences for use in a graph neural network model\n",
    "    :param protein_list: list of protein names\n",
    "    :param dataset_onehot: dataset containing protein sequence information\n",
    "    :return: adjacency matrix, feature matrix, and label list for each window of around Serine or Threonine location\n",
    "    \"\"\"\n",
    "    win_size = 10\n",
    "    mat_size = 2 * win_size + 1\n",
    "    feat_size = dataset_onehot.shape[1] - 4\n",
    "    name_list = []\n",
    "    adj_list = []\n",
    "    feat_list = []\n",
    "    label_list = []\n",
    "    for name in protein_list:\n",
    "        data = dataset_onehot[dataset_onehot['protein'] == name]\n",
    "        ST_index = np.where((data['SEQ_S'] == 1) | (data['SEQ_T'] == 1))[0]\n",
    "        for index in ST_index:\n",
    "            adj_matrix = np.eye(mat_size, k=-1) + np.eye(mat_size) + np.eye(mat_size, k=1)\n",
    "            feat_matrix = np.zeros((mat_size, feat_size))\n",
    "            label = data.iloc[[index], -2:].values\n",
    "\n",
    "            down_lim = index - win_size\n",
    "            up_lim = index + win_size\n",
    "            if down_lim < 0:\n",
    "                adj_matrix[:-down_lim, :-down_lim] = 0\n",
    "                feat_matrix[-down_lim:] = data.iloc[down_lim:up_lim, 2:-2].values\n",
    "            elif up_lim > len(data) - 1:\n",
    "                adj_matrix[len(data) - up_lim - 1:, len(data) - up_lim - 1:] = 0\n",
    "                feat_matrix[:len(data) - up_lim - 1] = data.iloc[down_lim:up_lim, 2:-2].values\n",
    "            else:\n",
    "                feat_matrix = data.iloc[down_lim:up_lim, 2:-2].values\n",
    "                \n",
    "            name_list.append(name)\n",
    "            adj_list.append(adj_matrix)\n",
    "            feat_list.append(feat_matrix)\n",
    "            label_list.append(label)\n",
    "    return np.array(name_list), np.array(adj_list), np.array(feat_list), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "391be5b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-19T00:26:55.763175Z",
     "start_time": "2023-01-19T00:26:55.701841Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (0,106) into shape (12,106)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgenerate_gnn_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprotein_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_onehot\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 27\u001b[0m, in \u001b[0;36mgenerate_gnn_dataset\u001b[1;34m(protein_list, dataset_onehot)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m down_lim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     26\u001b[0m     adj_matrix[:\u001b[38;5;241m-\u001b[39mdown_lim, :\u001b[38;5;241m-\u001b[39mdown_lim] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 27\u001b[0m     \u001b[43mfeat_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mdown_lim\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[down_lim:up_lim, \u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m up_lim \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     29\u001b[0m     adj_matrix[\u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m-\u001b[39m up_lim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:, \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m-\u001b[39m up_lim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (0,106) into shape (12,106)"
     ]
    }
   ],
   "source": [
    "generate_gnn_dataset(protein_list, dataset_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f03d726",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T14:19:35.412157Z",
     "start_time": "2023-01-17T14:19:35.384232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41432, 1, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(label_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ce2b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-18T23:35:54.785437Z",
     "start_time": "2023-01-18T23:35:53.798126Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c6153abe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T14:22:30.541165Z",
     "start_time": "2023-01-17T14:22:30.159845Z"
    }
   },
   "outputs": [],
   "source": [
    "paser = argparse.ArgumentParser()\n",
    "args = paser.parse_args(\"\")\n",
    "args.seed = 123\n",
    "args.val_size = 0.1\n",
    "args.test_size = 0.1\n",
    "args.shuffle = True\n",
    "\n",
    "class GCNDataset(Dataset):\n",
    "    def __init__(self, list_feature, list_adj, list_logP):\n",
    "        self.list_feature = list_feature\n",
    "        self.list_adj = list_adj\n",
    "        self.list_logP = list_logP\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.list_feature)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.list_feature[index], self.list_adj[index], self.list_logP[index]\n",
    "    \n",
    "def partition(list_feature, list_adj, list_logP, args):\n",
    "    num_total = list_feature.shape[0]\n",
    "    num_train = int(num_total * (1 - args.test_size - args.val_size))\n",
    "    num_val = int(num_total * args.val_size)\n",
    "    num_test = int(num_total * args.test_size)\n",
    "\n",
    "    feature_train = list_feature[:num_train]\n",
    "    adj_train = list_adj[:num_train]\n",
    "    logP_train = list_logP[:num_train]\n",
    "    feature_val = list_feature[num_train:num_train + num_val]\n",
    "    adj_val = list_adj[num_train:num_train + num_val]\n",
    "    logP_val = list_logP[num_train:num_train + num_val]\n",
    "    feature_test = list_feature[num_total - num_test:]\n",
    "    adj_test = list_adj[num_total - num_test:]\n",
    "    logP_test = list_logP[num_total - num_test:]\n",
    "        \n",
    "    train_set = GCNDataset(feature_train, adj_train, logP_train)\n",
    "    val_set = GCNDataset(feature_val, adj_val, logP_val)\n",
    "    test_set = GCNDataset(feature_test, adj_test, logP_test)\n",
    "\n",
    "    partition = {\n",
    "        'train': train_set,\n",
    "        'val': val_set,\n",
    "        'test': test_set\n",
    "    }\n",
    "\n",
    "    return partition\n",
    "\n",
    "dict_partition = partition(np.array(feat_list), np.array(adj_list), np.array(label_list), args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eabb8ea3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T13:27:12.048152Z",
     "start_time": "2023-01-17T13:27:12.028205Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9f39237",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T14:22:56.404590Z",
     "start_time": "2023-01-17T14:22:56.389598Z"
    }
   },
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, out_dim, n_amino, act=None, bn=False):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        \n",
    "        self.use_bn = bn\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        self.bn = nn.BatchNorm1d(n_amino)\n",
    "        self.activation = act\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        out = self.linear(x)\n",
    "        out = torch.matmul(adj, out)\n",
    "        if self.use_bn:\n",
    "            out = self.bn(out)\n",
    "        if self.activation != None:\n",
    "            out = self.activation(out)\n",
    "        return out, adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9a43cb2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T14:34:04.727085Z",
     "start_time": "2023-01-17T14:34:04.714117Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(net, partition, optimizer, criterion, args):\n",
    "    trainloader = torch.utils.data.DataLoader(partition['train'], \n",
    "                                              batch_size=args.train_batch_size, \n",
    "                                              shuffle=True, num_workers=2)\n",
    "    net.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad() # [21.01.05 오류 수정] 매 Epoch 마다 .zero_grad()가 실행되는 것을 매 iteration 마다 실행되도록 수정했습니다. \n",
    "\n",
    "        # get the inputs\n",
    "        list_feature, list_adj, list_label = data\n",
    "        list_feature = list_feature.cuda().float()\n",
    "        list_adj = list_adj.cuda().float()\n",
    "        list_label = list_label.cuda().float().view(-1, 1)\n",
    "        outputs = net(list_feature, list_adj)\n",
    "\n",
    "        loss = criterion(outputs, list_label)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = train_loss / len(trainloader)\n",
    "    return net, train_loss\n",
    "\n",
    "\n",
    "def validate(net, partition, criterion, args):\n",
    "    valloader = torch.utils.data.DataLoader(partition['val'], \n",
    "                                            batch_size=args.test_batch_size, \n",
    "                                            shuffle=False, num_workers=2)\n",
    "    net.eval()\n",
    "    val_loss = 0 \n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            list_feature, list_adj, list_label = data\n",
    "            list_feature = list_feature.cuda().float()\n",
    "            list_adj = list_adj.cuda().float()\n",
    "            list_label = list_label.cuda().float().view(-1, 1)\n",
    "            \n",
    "            outputs = net(list_feature, list_adj)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss = val_loss / len(valloader)\n",
    "    return val_loss\n",
    "\n",
    "# def test(net, partition, args):\n",
    "#     testloader = torch.utils.data.DataLoader(partition['test'], \n",
    "#                                              batch_size=args.test_batch_size, \n",
    "#                                              shuffle=False, num_workers=2)\n",
    "#     net.eval()\n",
    "#     with torch.no_grad():\n",
    "#         logP_total = list()\n",
    "#         pred_logP_total = list()\n",
    "#         for data in testloader:\n",
    "#             list_feature, list_adj, list_label = data\n",
    "#             list_feature = list_feature.cuda().float()\n",
    "#             list_adj = list_adj.cuda().float()\n",
    "#             list_label = list_label.cuda().float()\n",
    "#             label_total += list_label.tolist()\n",
    "#             list_label = list_label.view(-1, 1)\n",
    "            \n",
    "#             outputs = net(list_feature, list_adj)\n",
    "#             pred_label_total += outputs.view(-1).tolist()\n",
    "\n",
    "#         mae = mean_absolute_error(label_total, pred_label_total)\n",
    "#         std = np.std(np.array(label_total)-np.array(pred_label_total))\n",
    "    \n",
    "#     return mae, std, label_total, pred_label_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "67c254bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-17T14:35:13.196918Z",
     "start_time": "2023-01-17T14:35:13.179943Z"
    }
   },
   "outputs": [],
   "source": [
    "def experiment(partition, args):\n",
    "  \n",
    "    net = GCNNet(args)\n",
    "    net.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if args.optim == 'SGD':\n",
    "        optimizer = optim.SGD(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    elif args.optim == 'Adam':\n",
    "        optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.l2)\n",
    "    else:\n",
    "        raise ValueError('In-valid optimizer choice')\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "        \n",
    "    for epoch in range(args.epoch):  # loop over the dataset multiple times\n",
    "        ts = time.time()\n",
    "        net, train_loss = train(net, partition, optimizer, criterion, args)\n",
    "        val_loss = validate(net, partition, criterion, args)\n",
    "        te = time.time()\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        print('Epoch {}, Acc(train/val): {:2.2f}/{:2.2f}, Loss(train/val) {:2.2f}/{:2.2f}. Took {:2.2f} sec'.format(epoch, train_acc, val_acc, train_loss, val_loss, te-ts))\n",
    "        \n",
    "#     mae, std, logP_total, pred_logP_total = test(net, partition, args)    \n",
    "    \n",
    "    result = {}\n",
    "    result['train_losses'] = train_losses\n",
    "    result['val_losses'] = val_losses\n",
    "    result['mae'] = mae\n",
    "    result['std'] = std\n",
    "#     result['logP_total'] = logP_total\n",
    "#     result['pred_logP_total'] = pred_logP_total\n",
    "    return vars(args), result\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15898ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn",
   "language": "python",
   "name": "gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
