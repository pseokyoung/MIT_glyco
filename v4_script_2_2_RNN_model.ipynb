{"cells":[{"cell_type":"markdown","metadata":{"id":"ME7Efq_wYYBB"},"source":["## header"],"id":"ME7Efq_wYYBB"},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"elapsed":26139,"status":"ok","timestamp":1674416949081,"user":{"displayName":"SEOKYOUNG HONG","userId":"15432326928825214179"},"user_tz":300},"id":"7A7deAn_Ymi6","outputId":"d12177ab-46a0-4cef-a4db-ca522d2afa58"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Gproject/MIT_glyco'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","from os.path import exists\n","\n","project_path = '/content/drive/MyDrive/Gproject/MIT_glyco'\n","os.chdir(project_path)\n","\n","os.getcwd() # current working directory"],"id":"7A7deAn_Ymi6"},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1674416949082,"user":{"displayName":"SEOKYOUNG HONG","userId":"15432326928825214179"},"user_tz":300},"id":"ceeebd00"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import time\n","\n","version = 'v4'\n","update = False"],"id":"ceeebd00"},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":578},"executionInfo":{"elapsed":2854,"status":"ok","timestamp":1674416951929,"user":{"displayName":"SEOKYOUNG HONG","userId":"15432326928825214179"},"user_tz":300},"id":"92892710","outputId":"7a6345cc-86db-40b7-d8db-12596525f489"},"outputs":[{"output_type":"stream","name":"stdout","text":["total number of proteins:       272\n","total number of samples:        257578\n","total number of positive sites: 529\n","total number of negative sites: 257049\n"]},{"output_type":"display_data","data":{"text/plain":["           # SEQ SS    ASA    Phi    Psi  Theta(i-1=>i+1)  Tau(i-2=>i+2)  \\\n","0          1   M  C  112.7 -100.9  139.3            119.5          165.0   \n","1          2   T  C  103.3 -102.0  132.1            117.6         -150.0   \n","2          3   L  C   50.9  -97.8  134.7            118.5         -149.2   \n","3          4   P  C   77.2  -69.2  144.0            111.0         -105.3   \n","4          5   H  C   80.3  -95.4  141.5            118.6         -135.6   \n","...      ...  .. ..    ...    ...    ...              ...            ...   \n","257573  2892   E  C  110.1  -95.9  129.5            114.1         -151.5   \n","257574  2893   E  C  129.9  -89.6  124.2            111.0         -140.1   \n","257575  2894   T  C  106.7  -91.4  100.3            109.1         -163.0   \n","257576  2895   K  C  160.4  -89.3   66.8            107.1          136.5   \n","257577  2896   S  C   98.4  -91.9  113.0            110.0          100.4   \n","\n","        HSE_alpha_up  HSE_alpha_down  ...  side_3  side_4      side_5  nAli  \\\n","0                8.5             9.1  ...     pro   cycle       small     0   \n","1                3.8            13.9  ...   cycle   small         pro     0   \n","2               16.4            11.6  ...   small     pro         gly     0   \n","3                7.5            16.7  ...     pro     gly       small     1   \n","4               13.3            13.3  ...     gly   small  very_small     2   \n","...              ...             ...  ...     ...     ...         ...   ...   \n","257573           8.1            12.4  ...    long   small        None     1   \n","257574           5.4            11.0  ...   small    None        None     0   \n","257575           3.1             9.1  ...    None    None        None     0   \n","257576           2.7             7.7  ...    None    None        None     0   \n","257577           2.1             6.2  ...    None    None        None     0   \n","\n","       nPos nS/nT Proline phi_psi positivity protein  \n","0         0     3       0   alpha          0  A2ABU4  \n","1         0     3       0   alpha          0  A2ABU4  \n","2         0     3       1   alpha          0  A2ABU4  \n","3         0     3       0   alpha          0  A2ABU4  \n","4         0     3       0   alpha          0  A2ABU4  \n","...     ...   ...     ...     ...        ...     ...  \n","257573    1     3       0   alpha          0  Q9Y520  \n","257574    0     3       0   alpha          0  Q9Y520  \n","257575    0     3       0   alpha          0  Q9Y520  \n","257576    1     3       0   other          0  Q9Y520  \n","257577    1     3       0   alpha          0  Q9Y520  \n","\n","[257578 rows x 27 columns]"],"text/html":["\n","  <div id=\"df-98e5450c-3bf4-4645-94a8-556112c3a66c\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>#</th>\n","      <th>SEQ</th>\n","      <th>SS</th>\n","      <th>ASA</th>\n","      <th>Phi</th>\n","      <th>Psi</th>\n","      <th>Theta(i-1=&gt;i+1)</th>\n","      <th>Tau(i-2=&gt;i+2)</th>\n","      <th>HSE_alpha_up</th>\n","      <th>HSE_alpha_down</th>\n","      <th>...</th>\n","      <th>side_3</th>\n","      <th>side_4</th>\n","      <th>side_5</th>\n","      <th>nAli</th>\n","      <th>nPos</th>\n","      <th>nS/nT</th>\n","      <th>Proline</th>\n","      <th>phi_psi</th>\n","      <th>positivity</th>\n","      <th>protein</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>M</td>\n","      <td>C</td>\n","      <td>112.7</td>\n","      <td>-100.9</td>\n","      <td>139.3</td>\n","      <td>119.5</td>\n","      <td>165.0</td>\n","      <td>8.5</td>\n","      <td>9.1</td>\n","      <td>...</td>\n","      <td>pro</td>\n","      <td>cycle</td>\n","      <td>small</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>alpha</td>\n","      <td>0</td>\n","      <td>A2ABU4</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>T</td>\n","      <td>C</td>\n","      <td>103.3</td>\n","      <td>-102.0</td>\n","      <td>132.1</td>\n","      <td>117.6</td>\n","      <td>-150.0</td>\n","      <td>3.8</td>\n","      <td>13.9</td>\n","      <td>...</td>\n","      <td>cycle</td>\n","      <td>small</td>\n","      <td>pro</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>alpha</td>\n","      <td>0</td>\n","      <td>A2ABU4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>L</td>\n","      <td>C</td>\n","      <td>50.9</td>\n","      <td>-97.8</td>\n","      <td>134.7</td>\n","      <td>118.5</td>\n","      <td>-149.2</td>\n","      <td>16.4</td>\n","      <td>11.6</td>\n","      <td>...</td>\n","      <td>small</td>\n","      <td>pro</td>\n","      <td>gly</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>alpha</td>\n","      <td>0</td>\n","      <td>A2ABU4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>P</td>\n","      <td>C</td>\n","      <td>77.2</td>\n","      <td>-69.2</td>\n","      <td>144.0</td>\n","      <td>111.0</td>\n","      <td>-105.3</td>\n","      <td>7.5</td>\n","      <td>16.7</td>\n","      <td>...</td>\n","      <td>pro</td>\n","      <td>gly</td>\n","      <td>small</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>alpha</td>\n","      <td>0</td>\n","      <td>A2ABU4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>H</td>\n","      <td>C</td>\n","      <td>80.3</td>\n","      <td>-95.4</td>\n","      <td>141.5</td>\n","      <td>118.6</td>\n","      <td>-135.6</td>\n","      <td>13.3</td>\n","      <td>13.3</td>\n","      <td>...</td>\n","      <td>gly</td>\n","      <td>small</td>\n","      <td>very_small</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>alpha</td>\n","      <td>0</td>\n","      <td>A2ABU4</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>257573</th>\n","      <td>2892</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>110.1</td>\n","      <td>-95.9</td>\n","      <td>129.5</td>\n","      <td>114.1</td>\n","      <td>-151.5</td>\n","      <td>8.1</td>\n","      <td>12.4</td>\n","      <td>...</td>\n","      <td>long</td>\n","      <td>small</td>\n","      <td>None</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>alpha</td>\n","      <td>0</td>\n","      <td>Q9Y520</td>\n","    </tr>\n","    <tr>\n","      <th>257574</th>\n","      <td>2893</td>\n","      <td>E</td>\n","      <td>C</td>\n","      <td>129.9</td>\n","      <td>-89.6</td>\n","      <td>124.2</td>\n","      <td>111.0</td>\n","      <td>-140.1</td>\n","      <td>5.4</td>\n","      <td>11.0</td>\n","      <td>...</td>\n","      <td>small</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>alpha</td>\n","      <td>0</td>\n","      <td>Q9Y520</td>\n","    </tr>\n","    <tr>\n","      <th>257575</th>\n","      <td>2894</td>\n","      <td>T</td>\n","      <td>C</td>\n","      <td>106.7</td>\n","      <td>-91.4</td>\n","      <td>100.3</td>\n","      <td>109.1</td>\n","      <td>-163.0</td>\n","      <td>3.1</td>\n","      <td>9.1</td>\n","      <td>...</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>alpha</td>\n","      <td>0</td>\n","      <td>Q9Y520</td>\n","    </tr>\n","    <tr>\n","      <th>257576</th>\n","      <td>2895</td>\n","      <td>K</td>\n","      <td>C</td>\n","      <td>160.4</td>\n","      <td>-89.3</td>\n","      <td>66.8</td>\n","      <td>107.1</td>\n","      <td>136.5</td>\n","      <td>2.7</td>\n","      <td>7.7</td>\n","      <td>...</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>other</td>\n","      <td>0</td>\n","      <td>Q9Y520</td>\n","    </tr>\n","    <tr>\n","      <th>257577</th>\n","      <td>2896</td>\n","      <td>S</td>\n","      <td>C</td>\n","      <td>98.4</td>\n","      <td>-91.9</td>\n","      <td>113.0</td>\n","      <td>110.0</td>\n","      <td>100.4</td>\n","      <td>2.1</td>\n","      <td>6.2</td>\n","      <td>...</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>None</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>alpha</td>\n","      <td>0</td>\n","      <td>Q9Y520</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>257578 rows Ã— 27 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98e5450c-3bf4-4645-94a8-556112c3a66c')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-98e5450c-3bf4-4645-94a8-556112c3a66c button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-98e5450c-3bf4-4645-94a8-556112c3a66c');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["load_name = \"v4_data_all_sites.csv\"\n","dataset = pd.read_csv(load_name)\n","\n","positive_sites = dataset[dataset['positivity']==1]\n","negative_sites = dataset[dataset['positivity']==0]\n","\n","print(\"total number of proteins:      \", len(dataset.protein.unique()))\n","print(\"total number of samples:       \", len(dataset))\n","print(\"total number of positive sites:\", len(positive_sites))\n","print(\"total number of negative sites:\", len(negative_sites))\n","display(dataset)"],"id":"92892710"},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":660},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1674416951930,"user":{"displayName":"SEOKYOUNG HONG","userId":"15432326928825214179"},"user_tz":300},"id":"cb592ccc","outputId":"f5f2f818-3008-4754-be6e-d52d18935a5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 257578 entries, 0 to 257577\n","Data columns (total 27 columns):\n"," #   Column           Non-Null Count   Dtype  \n","---  ------           --------------   -----  \n"," 0   #                257578 non-null  int64  \n"," 1   SEQ              257578 non-null  object \n"," 2   SS               257578 non-null  object \n"," 3   ASA              257578 non-null  float64\n"," 4   Phi              257578 non-null  float64\n"," 5   Psi              257578 non-null  float64\n"," 6   Theta(i-1=>i+1)  257578 non-null  float64\n"," 7   Tau(i-2=>i+2)    257578 non-null  float64\n"," 8   HSE_alpha_up     257578 non-null  float64\n"," 9   HSE_alpha_down   257578 non-null  float64\n"," 10  P(C)             257578 non-null  float64\n"," 11  P(H)             257578 non-null  float64\n"," 12  P(E)             257578 non-null  float64\n"," 13  flexibility      257578 non-null  float64\n"," 14  side_-1          257578 non-null  object \n"," 15  side_1           257578 non-null  object \n"," 16  side_2           257578 non-null  object \n"," 17  side_3           257578 non-null  object \n"," 18  side_4           257578 non-null  object \n"," 19  side_5           257578 non-null  object \n"," 20  nAli             257578 non-null  int64  \n"," 21  nPos             257578 non-null  int64  \n"," 22  nS/nT            257578 non-null  int64  \n"," 23  Proline          257578 non-null  int64  \n"," 24  phi_psi          257578 non-null  object \n"," 25  positivity       257578 non-null  int64  \n"," 26  protein          257578 non-null  object \n","dtypes: float64(11), int64(6), object(10)\n","memory usage: 53.1+ MB\n"]},{"output_type":"display_data","data":{"text/plain":["None"]},"metadata":{}}],"source":["display(dataset.info())"],"id":"cb592ccc"},{"cell_type":"markdown","metadata":{"id":"def8ec9e"},"source":["## case 1: without window"],"id":"def8ec9e"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":733},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1674416951930,"user":{"displayName":"SEOKYOUNG HONG","userId":"15432326928825214179"},"user_tz":300},"id":"06d7578e","outputId":"5c98c0a1-86f9-4bb3-e1a1-3188d10d9afe"},"outputs":[{"output_type":"stream","name":"stdout","text":["(257578, 34)\n","(257578, 1)\n","\n","x columns:\n"]},{"output_type":"display_data","data":{"text/plain":["0                 ASA\n","1                 Phi\n","2                 Psi\n","3     Theta(i-1=>i+1)\n","4       Tau(i-2=>i+2)\n","5        HSE_alpha_up\n","6      HSE_alpha_down\n","7                P(C)\n","8                P(H)\n","9                P(E)\n","10        flexibility\n","11              SEQ_A\n","12              SEQ_C\n","13              SEQ_D\n","14              SEQ_E\n","15              SEQ_F\n","16              SEQ_G\n","17              SEQ_H\n","18              SEQ_I\n","19              SEQ_K\n","20              SEQ_L\n","21              SEQ_M\n","22              SEQ_N\n","23              SEQ_P\n","24              SEQ_Q\n","25              SEQ_R\n","26              SEQ_S\n","27              SEQ_T\n","28              SEQ_V\n","29              SEQ_W\n","30              SEQ_Y\n","31               SS_C\n","32               SS_E\n","33               SS_H\n","dtype: object"]},"metadata":{}}],"source":["x_cat = ['SEQ', 'SS']\n","x_cts = ['ASA', 'Phi', 'Psi', 'Theta(i-1=>i+1)', 'Tau(i-2=>i+2)', 'HSE_alpha_up', 'HSE_alpha_down', \n","         'P(C)', 'P(H)', 'P(E)', 'flexibility']\n","y_label = ['positivity']\n","\n","data_x = pd.get_dummies(dataset[x_cts+x_cat], columns=x_cat)\n","data_y = dataset[y_label]\n","\n","print(data_x.shape)\n","print(data_y.shape)\n","\n","print(\"\\nx columns:\")\n","display(pd.Series(data_x.columns))"],"id":"06d7578e"},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":16487,"status":"ok","timestamp":1674416968410,"user":{"displayName":"SEOKYOUNG HONG","userId":"15432326928825214179"},"user_tz":300},"id":"630c2cd3"},"outputs":[],"source":["input_data = data_x\n","output_data = data_y\n","window_size = 10\n","window_len  = 2 * window_size + 1\n","\n","protein_list = list(dataset.protein.unique())\n","rnn_input = []\n","rnn_output = []\n","for name in protein_list:\n","    data = dataset[dataset['protein']==name]\n","    low_bound = data.index[0]\n","    up_bound  = data.index[-1]\n","    ST_idx = np.where((data['SEQ']=='S')|(data['SEQ']=='T'))[0] + low_bound\n","    \n","    for idx in ST_idx:\n","        start_idx = idx - window_size\n","        end_idx   = idx + window_size + 1\n","        \n","#         print(f\"{name}, {low_bound}, {up_bound}, {start_idx}, {end_idx}\")\n","        if start_idx < low_bound:\n","            zeros = np.zeros((low_bound-start_idx,input_data.shape[1]))\n","            temp  = input_data.iloc[low_bound:end_idx].values\n","            temp  = np.concatenate([zeros, temp], axis=0)\n","            \n","        elif end_idx > up_bound + 1:\n","            zeros = np.zeros((end_idx-up_bound-1,input_data.shape[1]))\n","            temp  = input_data.iloc[start_idx:up_bound+1].values\n","            temp  = np.concatenate([temp, zeros], axis=0)\n","            \n","        else:\n","            temp  = input_data.iloc[start_idx:end_idx].values\n","            \n","        rnn_input.append(temp)\n","        rnn_output.append(output_data.iloc[idx].values)\n","        \n","rnn_input = np.array(rnn_input)\n","rnn_output = np.array(rnn_output)"],"id":"630c2cd3"},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":416,"status":"ok","timestamp":1674416968819,"user":{"displayName":"SEOKYOUNG HONG","userId":"15432326928825214179"},"user_tz":300},"id":"8abb4e7d"},"outputs":[],"source":["from sklearn.model_selection import StratifiedShuffleSplit\n","\n","def stratified_split(data_x, data_y, test_size=0.2, n_splits=1, random_state=1, dtype='arr'):\n","\n","    split = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n","    \n","    train_x, train_y, test_x, test_y  = [], [], [], []\n","    if dtype=='df':\n","        data_x = data_x.values\n","        data_y = data_y.values\n","    \n","    for train_index, test_index in split.split(data_x, data_y):\n","        train_x.append(data_x[train_index])\n","        train_y.append(data_y[train_index])\n","\n","        test_x.append(data_x[test_index])\n","        test_y.append(data_y[test_index])\n","        \n","    print(\"train/test dataset\")\n","    print(\"train:\", train_x[0].shape, train_y[0].shape)\n","    print(\"test:\", test_x[0].shape, test_y[0].shape)\n","    \n","    if n_splits == 1:\n","        return train_x[0],train_y[0], test_x[0], test_y[0]\n","    else:\n","        return train_x, train_y, test_x, test_y"],"id":"8abb4e7d"},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3053,"status":"ok","timestamp":1674416971869,"user":{"displayName":"SEOKYOUNG HONG","userId":"15432326928825214179"},"user_tz":300},"id":"e1df0358","outputId":"8e9c5fdd-a417-43cd-e592-4ba4c2e799b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["1th iteration\n","train: (33011, 21, 34) (33011, 1) check scale: 0.0 1.0\n","test:  (8253, 21, 34) (8253, 1) check scale: 0.0 1.0\n","2th iteration\n","train: (33011, 21, 34) (33011, 1) check scale: 0.0 1.0\n","test:  (8253, 21, 34) (8253, 1) check scale: 0.0 1.001001001001001\n","3th iteration\n","train: (33011, 21, 34) (33011, 1) check scale: 0.0 1.0\n","test:  (8253, 21, 34) (8253, 1) check scale: 0.0 1.0090634441087611\n","4th iteration\n","train: (33011, 21, 34) (33011, 1) check scale: 0.0 1.0\n","test:  (8253, 21, 34) (8253, 1) check scale: 0.0 1.0\n","5th iteration\n","train: (33011, 21, 34) (33011, 1) check scale: 0.0 1.0\n","test:  (8253, 21, 34) (8253, 1) check scale: 0.0 1.0006653359946773\n","6th iteration\n","train: (33011, 21, 34) (33011, 1) check scale: 0.0 1.0\n","test:  (8253, 21, 34) (8253, 1) check scale: 0.0 1.0\n","7th iteration\n","train: (33011, 21, 34) (33011, 1) check scale: 0.0 1.0\n","test:  (8253, 21, 34) (8253, 1) check scale: 0.0 1.0090634441087611\n","8th iteration\n","train: (33011, 21, 34) (33011, 1) check scale: 0.0 1.0\n","test:  (8253, 21, 34) (8253, 1) check scale: 0.0 1.0090634441087611\n","9th iteration\n","train: (33011, 21, 34) (33011, 1) check scale: 0.0 1.0\n","test:  (8253, 21, 34) (8253, 1) check scale: 0.0 1.0\n","10th iteration\n","train: (33011, 21, 34) (33011, 1) check scale: 0.0 1.0\n","test:  (8253, 21, 34) (8253, 1) check scale: 0.0 1.0\n"]}],"source":["### split data into train/test dataset ###\n","test_size = 0.2\n","n_splits = 10\n","random_state = 1\n","\n","split = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n","arr_x, arr_y = rnn_input, rnn_output # convert dataframe to nd-array \n","\n","i=1\n","train_idx_list, train_x_list, train_y_list, test_idx_list, test_x_list, test_y_list = [], [], [], [], [], []\n","for train_index, test_index in split.split(arr_x, arr_y):\n","    train_x = arr_x[train_index]\n","    train_y = arr_y[train_index]\n","    test_x = arr_x[test_index]\n","    test_y = arr_y[test_index]\n","    \n","    train_cts = train_x[:,:,:len(x_cts)]\n","    test_cts  = test_x[:,:,:len(x_cts)]\n","    \n","    x_min = train_cts.min(0).min(0)\n","    x_max = train_cts.max(0).max(0)\n","    \n","    train_x[:,:,:len(x_cts)] = (train_cts-x_min)/(x_max-x_min)\n","    test_x[:,:,:len(x_cts)] = (test_cts-x_min)/(x_max-x_min)\n","    \n","    print(f\"{i}th iteration\")\n","    print(\"train:\", train_x.shape, train_y.shape, \"check scale:\", train_x.min(), train_x.max())\n","    print(\"test: \", test_x.shape, test_y.shape, \"check scale:\", test_x.min(), test_x.max())\n","    \n","    train_idx_list.append(train_index)\n","    train_x_list.append(train_x)\n","    train_y_list.append(train_y)\n","    \n","    test_idx_list.append(test_index)\n","    test_x_list.append(test_x)\n","    test_y_list.append(test_y)\n","    \n","    i += 1"],"id":"e1df0358"},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3060,"status":"ok","timestamp":1674416974924,"user":{"displayName":"SEOKYOUNG HONG","userId":"15432326928825214179"},"user_tz":300},"id":"52d731b1","outputId":"212b2bef-38a6-4e88-e91d-cbde2451f8d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["up-sampled train dataset: (65188, 21, 34) (65188, 1)\n","test dataset: (8253, 21, 34) (8253, 1)\n"]}],"source":["## upsampling dataset \n","import random\n","random_state = random_state\n","\n","upsample_x_list, upsample_y_list = [], []\n","for train_x, train_y in zip(train_x_list, train_y_list):\n","    index_pos = np.where(train_y == 1)[0]\n","    index_neg = np.where(train_y == 0)[0]\n","\n","    random.seed(random_state)\n","    up_index = [random.choice(index_pos) for _ in range(len(index_neg))] # get samples from positive sites as much as the number of negative sites\n","\n","    upsample_pos_x = train_x[up_index]\n","    upsample_pos_y = train_y[up_index]\n","    sample_neg_x = train_x[index_neg]\n","    sample_neg_y = train_y[index_neg]\n","\n","    sample_x = np.concatenate([upsample_pos_x, sample_neg_x], axis=0)\n","    sample_y = np.concatenate([upsample_pos_y, sample_neg_y], axis=0)\n","\n","    shuffle_index = np.arange(len(sample_x))\n","    np.random.seed(random_state)\n","    np.random.shuffle(shuffle_index)\n","    sample_x = sample_x[shuffle_index]\n","    sample_y = sample_y[shuffle_index]\n","    \n","    upsample_x_list.append(sample_x)\n","    upsample_y_list.append(sample_y)\n","\n","print(\"up-sampled train dataset:\", sample_x.shape, sample_y.shape)\n","print(\"test dataset:\", test_x.shape, test_y.shape)"],"id":"52d731b1"},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3216,"status":"ok","timestamp":1674416978135,"user":{"displayName":"SEOKYOUNG HONG","userId":"15432326928825214179"},"user_tz":300},"id":"74b1ea4b"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import *\n","from keras.models import Model\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","\n","from tensorflow.keras.optimizers import Adam\n","\n","def ClassifierLSTM(\n","    history_size, history_dim, class_num,\n","    rnn_layers = 1, rnn_neurons = 100,\n","    dense_layers = 1, dense_neurons = 100,\n","    optimizer = Adam(learning_rate = 0.001, beta_1=0.9, beta_2=0.999), loss=\"binary_crossentropy\", metrics = ['accuracy']\n","):\n","    encoder_input = Input(shape=(history_size, history_dim), name='input_encoder')\n","    \n","    # encoder module\n","    if rnn_layers == 1:\n","        encoder_output, state_h, state_c = LSTM(rnn_neurons, return_state=True, name='encoder_last')(encoder_input)\n","        # encoder_states = [state_h, state_c]\n","        \n","    else:\n","        for i in range(rnn_layers):\n","            #first encoder layer\n","            if i==0: \n","                encoder_output = LSTM(rnn_neurons, return_sequences=True, name=\"encoder_1\")(encoder_input)\n","            #mediate encoder layer\n","            elif i < rnn_layers-1: \n","                encoder_output = LSTM(rnn_neurons, return_sequences=True, name=f\"encoder_{i+1}\")(encoder_output)\n","            #last encoder layer\n","            else: \n","                encoder_output, state_h, state_c  = LSTM(rnn_neurons, return_state=True, name=f\"encoder_last\")(encoder_output)\n","                # encoder_states = [state_h, state_c]\n","    \n","    # dense module\n","    if dense_layers == 1:\n","        dense_output = Dense(dense_neurons, name='dense_1')(encoder_output)\n","    else:\n","        for i in range(dense_layers):\n","            #first dense layer\n","            \n","            if i==0:\n","                dense_output = Dense(dense_neurons, name='dense_1')(encoder_output)\n","            #mediate encoder layer\n","            else:\n","                dense_output = Dense(dense_neurons, name=f'dense_{i+1}')(dense_output)\n","    dense_output = Dense(class_num, activation='sigmoid', name=f'dense_last')(dense_output)  \n","    \n","    # model compile\n","    model = Model(encoder_input, dense_output)\n","    model.compile(loss=loss,optimizer = optimizer, metrics=metrics)\n","    \n","    return model"],"id":"74b1ea4b"},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1674416978135,"user":{"displayName":"SEOKYOUNG HONG","userId":"15432326928825214179"},"user_tz":300},"id":"9784712e"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from seaborn import heatmap\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","def scores(y_real, y_pred, rounding=4):\n","    \n","    accuracy  = 100*np.array(accuracy_score(y_real, y_pred)).round(rounding)\n","    precision = 100*np.array(precision_score(y_real, y_pred, average=None)).round(rounding)[1]\n","    recall    = 100*np.array(recall_score(y_real, y_pred, average=None)).round(rounding)[1]\n","    f1        = 100*np.array(f1_score(y_real, y_pred, average=None)).round(rounding)[1]\n","    \n","    return accuracy, precision, recall, f1"],"id":"9784712e"},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b5fedc0b","executionInfo":{"status":"ok","timestamp":1674417021356,"user_tz":300,"elapsed":43226,"user":{"displayName":"SEOKYOUNG HONG","userId":"15432326928825214179"}},"outputId":"6a48fa24-9746-4636-f6d2-f7fb9e56730b"},"outputs":[{"output_type":"stream","name":"stdout","text":["random, 1 of 30: 2 layers, 256 neurons, 2 layers, 64 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_1of30.csv\n","random, 2 of 30: 1 layers, 16 neurons, 2 layers, 64 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_2of30.csv\n","random, 3 of 30: 2 layers, 256 neurons, 9 layers, 32 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_3of30.csv\n","random, 4 of 30: 2 layers, 64 neurons, 2 layers, 128 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_4of30.csv\n","random, 5 of 30: 3 layers, 64 neurons, 9 layers, 16 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_5of30.csv\n","random, 6 of 30: 1 layers, 128 neurons, 5 layers, 16 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_6of30.csv\n","random, 7 of 30: 3 layers, 32 neurons, 7 layers, 16 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_7of30.csv\n","random, 8 of 30: 2 layers, 64 neurons, 7 layers, 32 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_8of30.csv\n","random, 9 of 30: 4 layers, 256 neurons, 6 layers, 64 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_9of30.csv\n","random, 10 of 30: 1 layers, 128 neurons, 8 layers, 256 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_10of30.csv\n","random, 11 of 30: 4 layers, 256 neurons, 8 layers, 128 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_11of30.csv\n","random, 12 of 30: 4 layers, 64 neurons, 9 layers, 64 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_12of30.csv\n","random, 13 of 30: 3 layers, 64 neurons, 3 layers, 32 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_13of30.csv\n","random, 14 of 30: 1 layers, 256 neurons, 9 layers, 32 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_14of30.csv\n","random, 15 of 30: 2 layers, 16 neurons, 9 layers, 16 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_15of30.csv\n","random, 16 of 30: 3 layers, 128 neurons, 8 layers, 64 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_16of30.csv\n","random, 17 of 30: 4 layers, 64 neurons, 6 layers, 64 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_17of30.csv\n","random, 18 of 30: 2 layers, 16 neurons, 8 layers, 64 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_18of30.csv\n","random, 19 of 30: 1 layers, 256 neurons, 2 layers, 256 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_19of30.csv\n","random, 20 of 30: 2 layers, 64 neurons, 2 layers, 64 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_20of30.csv\n","random, 21 of 30: 2 layers, 128 neurons, 7 layers, 64 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_21of30.csv\n","random, 22 of 30: 2 layers, 32 neurons, 1 layers, 256 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_22of30.csv\n","random, 23 of 30: 3 layers, 16 neurons, 1 layers, 256 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_23of30.csv\n","random, 24 of 30: 4 layers, 256 neurons, 3 layers, 32 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_24of30.csv\n","random, 25 of 30: 4 layers, 16 neurons, 4 layers, 64 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_25of30.csv\n","random, 26 of 30: 2 layers, 32 neurons, 7 layers, 256 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_26of30.csv\n","random, 27 of 30: 4 layers, 64 neurons, 5 layers, 32 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_27of30.csv\n","random, 28 of 30: 1 layers, 32 neurons, 9 layers, 256 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_28of30.csv\n","random, 29 of 30: 1 layers, 64 neurons, 10 layers, 256 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_29of30.csv\n","random, 30 of 30: 3 layers, 256 neurons, 1 layers, 256 neurons\n","history is loaded from: ./score/v4_RNN_without_window_hpo_30of30.csv\n"]}],"source":["## hyper-parameter optimization\n","model_type = 'RNN_without_window'\n","\n","valid_size = test_size/(1-test_size)\n","patience = 30\n","monitor = 'val_loss'\n","random_state = random_state\n","early_stopping_cb = EarlyStopping(patience=patience, restore_best_weights=True, monitor=monitor)\n","\n","parameter_config = {\n","    \"rnn_layers\" : range(1,5),\n","    \"rnn_neurons\" : [16, 32, 64, 128, 256],\n","    \"dnn_layers\" : range(1,11),\n","    \"dnn_neurons\" : [16, 32, 64, 128, 256],\n","}\n","\n","method = \"random\"\n","counts = 30\n","metrics = ['time', 'rnn_layers', 'rnn_neurons', 'dnn_layers', 'dnn_neurons', \n","           'loss', 'val_loss', 'test_loss', 'accuracy', 'precision', 'recall', 'f1']\n","\n","\n","train_x = upsample_x_list[0]\n","train_y = upsample_y_list[0]\n","test_x = test_x_list[0]\n","test_y = test_y_list[0]\n","\n","hpo_result = pd.DataFrame([], columns=metrics)\n","for i in range(counts):\n","    random.seed(i+1)\n","    rnn_layers = random.choice(parameter_config[\"rnn_layers\"])\n","    rnn_neurons = random.choice(parameter_config[\"rnn_neurons\"])\n","    dnn_layers = random.choice(parameter_config[\"dnn_layers\"])\n","    dnn_neurons = random.choice(parameter_config[\"dnn_neurons\"])\n","    print(f\"random, {i+1} of {counts}: {rnn_layers} layers, {rnn_neurons} neurons, {dnn_layers} layers, {dnn_neurons} neurons\")\n","    \n","    model_name = f'{version}_{model_type}_hpo_{i+1}of{counts}'\n","    save_path  = f'./model/{model_name}.h5'\n","    score_path = f\"./score/{model_name}.csv\"\n","    \n","    history_size = train_x.shape[1]\n","    history_dim = train_x.shape[2]\n","    y_dim = train_y.shape[1]\n","    \n","    model = ClassifierLSTM(history_size, history_dim, y_dim,\n","                           rnn_layers = rnn_layers, rnn_neurons = rnn_neurons,\n","                           dense_layers = dnn_layers, dense_neurons = dnn_neurons) \n","\n","    if not exists(save_path) or update:\n","        tf.random.set_seed(i+1)\n","        \n","        time_start = time.time()\n","        history = model.fit(train_x, train_y, verbose=0,\n","                            epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n","        time_end = time.time()\n","        time_elapse = round((time_end - time_start)/60, 3)\n","        \n","        model.save_weights(save_path)\n","        print(f\"model is saved to: {save_path}\")\n","        \n","        idx = np.array(history.history[monitor]).argmin()\n","        val_loss = history.history['val_loss'][idx]\n","        loss = history.history['loss'][idx]\n","        test_loss = model.evaluate(test_x, test_y, verbose=0)[0]\n","        prediction = model.predict(test_x, verbose=0)\n","        prediction = prediction.round(0).astype(int)\n","        y_real = test_y\n","        y_pred = prediction\n","        accuracy, precision, recall, f1 = scores(y_real, y_pred)\n","        scores_df = pd.DataFrame([[time_elapse, rnn_layers, rnn_neurons, dnn_layers, dnn_neurons, \n","                                   loss, val_loss, test_loss, accuracy, precision, recall, f1]], \n","                                  columns=metrics)\n","\n","        scores_df.to_csv(score_path)\n","        print(f\"history is saved to: {score_path}\")\n","\n","    else:\n","        scores_df = pd.read_csv(score_path, index_col=0, header=0)\n","        print(f\"history is loaded from: {score_path}\")\n","        \n","    hpo_result = pd.concat([hpo_result, scores_df], axis=0)\n","\n","hpo_result = hpo_result.reset_index(drop=True)"],"id":"b5fedc0b"},{"cell_type":"code","execution_count":13,"metadata":{"id":"d88082fd","colab":{"base_uri":"https://localhost:8080/","height":557},"executionInfo":{"status":"ok","timestamp":1674417021356,"user_tz":300,"elapsed":17,"user":{"displayName":"SEOKYOUNG HONG","userId":"15432326928825214179"}},"outputId":"3f4893a3-3560-4086-8ad0-c3498869ca8e"},"outputs":[{"output_type":"stream","name":"stdout","text":["best hyperparamerter: index 26\n"]},{"output_type":"display_data","data":{"text/plain":["time             28.641\n","rnn_layers            4\n","rnn_neurons          64\n","dnn_layers            5\n","dnn_neurons          32\n","loss           0.002482\n","val_loss       0.016598\n","test_loss      0.150824\n","accuracy          98.32\n","precision         26.03\n","recall            18.27\n","f1                21.47\n","Name: 26, dtype: object"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["            time       loss   val_loss  test_loss   accuracy  precision  \\\n","count  30.000000  30.000000  30.000000  30.000000  30.000000  30.000000   \n","mean   18.248633   0.030020   0.040725   0.265071  98.102333  20.167333   \n","std     7.805233   0.125914   0.123697   0.161986   0.453551   9.063924   \n","min     6.981000   0.000457   0.006680   0.106001  97.150000   0.000000   \n","25%    12.415500   0.001340   0.010482   0.156384  97.780000  14.087500   \n","50%    16.743500   0.004353   0.015007   0.199327  98.275000  20.330000   \n","75%    22.815750   0.007651   0.023507   0.348742  98.437500  25.777500   \n","max    35.320000   0.693187   0.693131   0.688893  98.740000  44.000000   \n","\n","          recall         f1  \n","count  30.000000  30.000000  \n","mean   13.622333  15.297000  \n","std     4.180420   4.270977  \n","min     0.000000   0.000000  \n","25%    11.540000  12.807500  \n","50%    13.460000  15.680000  \n","75%    16.350000  18.422500  \n","max    22.120000  21.470000  "],"text/html":["\n","  <div id=\"df-b9e9c028-703f-493f-8cd8-4aa7d3b73309\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>time</th>\n","      <th>loss</th>\n","      <th>val_loss</th>\n","      <th>test_loss</th>\n","      <th>accuracy</th>\n","      <th>precision</th>\n","      <th>recall</th>\n","      <th>f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>30.000000</td>\n","      <td>30.000000</td>\n","      <td>30.000000</td>\n","      <td>30.000000</td>\n","      <td>30.000000</td>\n","      <td>30.000000</td>\n","      <td>30.000000</td>\n","      <td>30.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>18.248633</td>\n","      <td>0.030020</td>\n","      <td>0.040725</td>\n","      <td>0.265071</td>\n","      <td>98.102333</td>\n","      <td>20.167333</td>\n","      <td>13.622333</td>\n","      <td>15.297000</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>7.805233</td>\n","      <td>0.125914</td>\n","      <td>0.123697</td>\n","      <td>0.161986</td>\n","      <td>0.453551</td>\n","      <td>9.063924</td>\n","      <td>4.180420</td>\n","      <td>4.270977</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>6.981000</td>\n","      <td>0.000457</td>\n","      <td>0.006680</td>\n","      <td>0.106001</td>\n","      <td>97.150000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>12.415500</td>\n","      <td>0.001340</td>\n","      <td>0.010482</td>\n","      <td>0.156384</td>\n","      <td>97.780000</td>\n","      <td>14.087500</td>\n","      <td>11.540000</td>\n","      <td>12.807500</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>16.743500</td>\n","      <td>0.004353</td>\n","      <td>0.015007</td>\n","      <td>0.199327</td>\n","      <td>98.275000</td>\n","      <td>20.330000</td>\n","      <td>13.460000</td>\n","      <td>15.680000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>22.815750</td>\n","      <td>0.007651</td>\n","      <td>0.023507</td>\n","      <td>0.348742</td>\n","      <td>98.437500</td>\n","      <td>25.777500</td>\n","      <td>16.350000</td>\n","      <td>18.422500</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>35.320000</td>\n","      <td>0.693187</td>\n","      <td>0.693131</td>\n","      <td>0.688893</td>\n","      <td>98.740000</td>\n","      <td>44.000000</td>\n","      <td>22.120000</td>\n","      <td>21.470000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9e9c028-703f-493f-8cd8-4aa7d3b73309')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b9e9c028-703f-493f-8cd8-4aa7d3b73309 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b9e9c028-703f-493f-8cd8-4aa7d3b73309');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["# show the HPO result\n","target_metric = 'f1'\n","best_idx = hpo_result[target_metric].argmax()\n","best_parameters = hpo_result.iloc[best_idx]\n","print(f'best hyperparamerter: index {best_idx}')\n","display(best_parameters)\n","\n","display(hpo_result.describe())"],"id":"d88082fd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"44c5c1b7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c6b7619c-b81c-4d3f-a2e1-1bf76b37a9a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["1th iteration\n"]}],"source":["# bulid model\n","rnn_layers = best_parameters['rnn_layers']\n","rnn_neurons = best_parameters['rnn_neurons']\n","dnn_layers = best_parameters['dnn_layers']\n","dnn_neurons = best_parameters['dnn_neurons']\n","\n","i=1\n","for train_x, train_y in zip(upsample_x_list, upsample_y_list):\n","    print(f\"{i}th iteration\")\n","    model_name = f'{version}_{model_type}_{rnn_layers}_{rnn_neurons}_{dnn_layers}_{dnn_neurons}_cv_{i}of{n_splits}'\n","    save_path  = f'./model/{model_name}.h5'\n","    \n","    if not exists(save_path) or update:\n","        history_size = train_x.shape[1]\n","        history_dim = train_x.shape[2]\n","        y_dim = train_y.shape[1]\n","        model = ClassifierLSTM(history_size, history_dim, y_dim,\n","                               rnn_layers = rnn_layers, rnn_neurons = rnn_neurons,\n","                               dense_layers = dnn_layers, dense_neurons = dnn_neurons) \n","\n","        if not exists(save_path) or update:\n","            tf.random.set_seed(random_state)\n","            history = model.fit(train_x, train_y, verbose=0,\n","                                epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n","            model.save_weights(save_path)\n","            print(f\"model is saved to: {save_path}\")\n","    else:\n","        print(f\"model already exists at: {save_path}\")\n","    i += 1\n","display(model.summary())"],"id":"44c5c1b7"},{"cell_type":"code","execution_count":null,"metadata":{"id":"04ff491b","scrolled":true},"outputs":[],"source":["# evaluate the trained model\n","i=1\n","accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n","for test_x, test_y in zip(test_x_list, test_y_list):\n","    model_name = f'{version}_{model_type}_{rnn_layers}_{rnn_neurons}_{dnn_layers}_{dnn_neurons}_cv_{i}of{n_splits}'\n","    save_path  = f'./model/{model_name}.h5'\n","    \n","    model = ClassifierLSTM(history_size, history_dim, y_dim,\n","                               rnn_layers = rnn_layers, rnn_neurons = rnn_neurons,\n","                               dense_layers = dnn_layers, dense_neurons = dnn_neurons) \n","    model.load_weights(save_path)\n","    \n","    prediction = model.predict(test_x, verbose=0)\n","    prediction = prediction.round(0).astype(int)\n","\n","    y_real = test_y\n","    y_pred = prediction\n","    \n","    accuracy  = 100*np.array(accuracy_score(y_real, y_pred)).round(4)\n","    precision = 100*np.array(precision_score(y_real, y_pred, average=None)).round(4)[1]\n","    recall    = 100*np.array(recall_score(y_real, y_pred, average=None)).round(4)[1]\n","    f1        = 100*np.array(f1_score(y_real, y_pred, average=None)).round(4)[1]\n","    \n","    accuracy_list.append(accuracy)\n","    precision_list.append(precision)\n","    recall_list.append(recall)\n","    f1_list.append(f1)\n","    \n","accuracies = np.array(accuracy_list)\n","precisions = np.array(precision_list)\n","recalls = np.array(recall_list)\n","f1s = np.array(f1_list)\n","\n","results = pd.DataFrame(np.array([accuracies, precisions, recalls, f1s]).T, columns=['accuracy', 'precision', 'recall', 'f1-score'])\n","results.describe()"],"id":"04ff491b"},{"cell_type":"markdown","metadata":{"id":"84a98239"},"source":["## case 1: with window"],"id":"84a98239"},{"cell_type":"code","execution_count":null,"metadata":{"id":"11b304ac"},"outputs":[],"source":["x_cat = ['SEQ', 'nS/nT', 'nAli', 'nPos', 'phi_psi', 'SS', \n","         'side_-1', 'side_1', 'side_2', 'side_3','side_4', 'side_5']\n","x_cts = ['Proline', 'flexibility']\n","y_label = ['positivity']\n","\n","data_x = pd.get_dummies(dataset[x_cts+x_cat], columns=x_cat)\n","data_y = dataset[y_label]\n","\n","print(data_x.shape)\n","print(data_y.shape)\n","\n","print(\"\\nx columns:\")\n","display(pd.Series(data_x.columns))"],"id":"11b304ac"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8421038e"},"outputs":[],"source":["input_data = data_x\n","output_data = data_y\n","\n","protein_list = list(dataset.protein.unique())\n","rnn_input = []\n","rnn_output = []\n","for name in protein_list:\n","    data = dataset[dataset['protein']==name]\n","    low_bound = data.index[0]\n","    up_bound  = data.index[-1]\n","    ST_idx = np.where((data['SEQ']=='S')|(data['SEQ']=='T'))[0] + low_bound\n","    \n","    for idx in ST_idx:\n","        start_idx = idx - window_size\n","        end_idx   = idx + window_size + 1\n","        \n","#         print(f\"{name}, {low_bound}, {up_bound}, {start_idx}, {end_idx}\")\n","        if start_idx < low_bound:\n","            zeros = np.zeros((low_bound-start_idx,input_data.shape[1]))\n","            temp  = input_data.iloc[low_bound:end_idx].values\n","            temp  = np.concatenate([zeros, temp], axis=0)\n","            \n","        elif end_idx > up_bound + 1:\n","            zeros = np.zeros((end_idx-up_bound-1,input_data.shape[1]))\n","            temp  = input_data.iloc[start_idx:up_bound+1].values\n","            temp  = np.concatenate([temp, zeros], axis=0)\n","            \n","        else:\n","            temp  = input_data.iloc[start_idx:end_idx].values\n","            \n","        rnn_input.append(temp)\n","        rnn_output.append(output_data.iloc[idx].values)\n","        \n","rnn_input = np.array(rnn_input)\n","rnn_output = np.array(rnn_output)"],"id":"8421038e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"15c71bf1"},"outputs":[],"source":["### split data into train/test dataset ###\n","split = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=random_state)\n","arr_x, arr_y = rnn_input, rnn_output # convert dataframe to nd-array \n","\n","i=1\n","train_idx_list, train_x_list, train_y_list, test_idx_list, test_x_list, test_y_list = [], [], [], [], [], []\n","for train_index, test_index in split.split(arr_x, arr_y):\n","    train_x = arr_x[train_index]\n","    train_y = arr_y[train_index]\n","    test_x = arr_x[test_index]\n","    test_y = arr_y[test_index]\n","    \n","    train_cts = train_x[:,:,:len(x_cts)]\n","    test_cts  = test_x[:,:,:len(x_cts)]\n","    \n","    x_min = train_cts.min(0).min(0)\n","    x_max = train_cts.max(0).max(0)\n","    \n","    train_x[:,:,:len(x_cts)] = (train_cts-x_min)/(x_max-x_min)\n","    test_x[:,:,:len(x_cts)] = (test_cts-x_min)/(x_max-x_min)\n","    \n","    print(f\"{i}th iteration\")\n","    print(\"train:\", train_x.shape, train_y.shape, \"check scale:\", train_x.min(), train_x.max())\n","    print(\"test: \", test_x.shape, test_y.shape, \"check scale:\", test_x.min(), test_x.max())\n","    \n","    train_idx_list.append(train_index)\n","    train_x_list.append(train_x)\n","    train_y_list.append(train_y)\n","    \n","    test_idx_list.append(test_index)\n","    test_x_list.append(test_x)\n","    test_y_list.append(test_y)\n","    \n","    i += 1"],"id":"15c71bf1"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4c2e3498"},"outputs":[],"source":["## upsampling dataset \n","random_state = random_state\n","\n","upsample_x_list, upsample_y_list = [], []\n","for train_x, train_y in zip(train_x_list, train_y_list):\n","    index_pos = np.where(train_y == 1)[0]\n","    index_neg = np.where(train_y == 0)[0]\n","\n","    random.seed(random_state)\n","    up_index = [random.choice(index_pos) for _ in range(len(index_neg))] # get samples from positive sites as much as the number of negative sites\n","\n","    upsample_pos_x = train_x[up_index]\n","    upsample_pos_y = train_y[up_index]\n","    sample_neg_x = train_x[index_neg]\n","    sample_neg_y = train_y[index_neg]\n","\n","    sample_x = np.concatenate([upsample_pos_x, sample_neg_x], axis=0)\n","    sample_y = np.concatenate([upsample_pos_y, sample_neg_y], axis=0)\n","\n","    shuffle_index = np.arange(len(sample_x))\n","    np.random.seed(random_state)\n","    np.random.shuffle(shuffle_index)\n","    sample_x = sample_x[shuffle_index]\n","    sample_y = sample_y[shuffle_index]\n","    \n","    upsample_x_list.append(sample_x)\n","    upsample_y_list.append(sample_y)\n","\n","print(\"up-sampled train dataset:\", sample_x.shape, sample_y.shape)\n","print(\"test dataset:\", test_x.shape, test_y.shape)"],"id":"4c2e3498"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0b215712"},"outputs":[],"source":["## hyper-parameter optimization\n","model_type = 'RNN_without_window'\n","\n","train_x = upsample_x_list[0]\n","train_y = upsample_y_list[0]\n","test_x = test_x_list[0]\n","test_y = test_y_list[0]\n","\n","hpo_result = pd.DataFrame([], columns=metrics)\n","for i in range(counts):\n","    random.seed(i+1)\n","    rnn_layers = random.choice(parameter_config[\"rnn_layers\"])\n","    rnn_neurons = random.choice(parameter_config[\"rnn_neurons\"])\n","    dnn_layers = random.choice(parameter_config[\"dnn_layers\"])\n","    dnn_neurons = random.choice(parameter_config[\"dnn_neurons\"])\n","    print(f\"random, {i+1} of {counts}: {rnn_layers} layers, {rnn_neurons} neurons, {dnn_layers} layers, {dnn_neurons} neurons\")\n","    \n","    model_name = f'{version}_{model_type}_hpo_{i+1}of{counts}'\n","    save_path  = f'./model/{model_name}.h5'\n","    score_path = f\"./score/{model_name}.csv\"\n","    \n","    history_size = train_x.shape[1]\n","    history_dim = train_x.shape[2]\n","    y_dim = train_y.shape[1]\n","    \n","    model = ClassifierLSTM(history_size, history_dim, y_dim,\n","                           rnn_layers = rnn_layers, rnn_neurons = rnn_neurons,\n","                           dense_layers = dnn_layers, dense_neurons = dnn_neurons) \n","\n","    if not exists(save_path) or update:\n","        tf.random.set_seed(i+1)\n","        \n","        time_start = time.time()\n","        history = model.fit(train_x, train_y, verbose=0,\n","                            epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n","        time_end = time.time()\n","        time_elapse = round((time_end - time_start)/60, 3)\n","        \n","        model.save_weights(save_path)\n","        print(f\"model is saved to: {save_path}\")\n","        \n","        idx = np.array(history.history[monitor]).argmin()\n","        val_loss = history.history['val_loss'][idx]\n","        loss = history.history['loss'][idx]\n","        test_loss = model.evaluate(test_x, test_y, verbose=0)[0]\n","        prediction = model.predict(test_x, verbose=0)\n","        prediction = prediction.round(0).astype(int)\n","        y_real = test_y\n","        y_pred = prediction\n","        accuracy, precision, recall, f1 = scores(y_real, y_pred)\n","        scores_df = pd.DataFrame([[time_elapse, rnn_layers, rnn_neurons, dnn_layers, dnn_neurons, \n","                                   loss, val_loss, test_loss, accuracy, precision, recall, f1]], \n","                                  columns=metrics)\n","\n","        scores_df.to_csv(score_path)\n","        print(f\"history is saved to: {score_path}\")\n","\n","    else:\n","        scores_df = pd.read_csv(score_path, index_col=0, header=0)\n","        print(f\"history is loaded from: {score_path}\")\n","        \n","    hpo_result = pd.concat([hpo_result, scores_df], axis=0)\n","\n","hpo_result = hpo_result.reset_index(drop=True)"],"id":"0b215712"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d35c571e"},"outputs":[],"source":["# show the HPO result\n","target_metric = 'f1'\n","best_idx = hpo_result[target_metric].argmax()\n","best_parameters = hpo_result.iloc[best_idx]\n","print(f'best hyperparamerter: index {best_idx}')\n","display(best_parameters)\n","\n","display(hpo_result.describe())"],"id":"d35c571e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d31965ce"},"outputs":[],"source":["# bulid model\n","rnn_layers = best_parameters['rnn_layers']\n","rnn_neurons = best_parameters['rnn_neurons']\n","dnn_layers = best_parameters['dnn_layers']\n","dnn_neurons = best_parameters['dnn_neurons']\n","\n","i=1\n","for train_x, train_y in zip(upsample_x_list, upsample_y_list):\n","    print(f\"{i}th iteration\")\n","    model_name = f'{version}_{model_type}_{rnn_layers}_{rnn_neurons}_{dnn_layers}_{dnn_neurons}_cv_{i}of{n_splits}'\n","    save_path  = f'./model/{model_name}.h5'\n","    \n","    if not exists(save_path) or update:\n","        history_size = train_x.shape[1]\n","        history_dim = train_x.shape[2]\n","        y_dim = train_y.shape[1]\n","        model = ClassifierLSTM(history_size, history_dim, y_dim,\n","                               rnn_layers = rnn_layers, rnn_neurons = rnn_neurons,\n","                               dense_layers = dnn_layers, dense_neurons = dnn_neurons) \n","\n","        if not exists(save_path) or update:\n","            tf.random.set_seed(random_state)\n","            history = model.fit(train_x, train_y, verbose=0,\n","                                epochs=10000, callbacks=[early_stopping_cb], validation_split= valid_size)\n","            model.save_weights(save_path)\n","            print(f\"model is saved to: {save_path}\")\n","    else:\n","        print(f\"model already exists at: {save_path}\")\n","    i += 1\n","display(model.summary())"],"id":"d31965ce"},{"cell_type":"code","execution_count":null,"metadata":{"id":"473d2f8b","scrolled":true},"outputs":[],"source":["# evaluate the trained model\n","i=1\n","accuracy_list, precision_list, recall_list, f1_list = [], [], [], []\n","for test_x, test_y in zip(test_x_list, test_y_list):\n","    model_name = f'{version}_{model_type}_{rnn_layers}_{rnn_neurons}_{dnn_layers}_{dnn_neurons}_cv_{i}of{n_splits}'\n","    save_path  = f'./model/{model_name}.h5'\n","    \n","    model = ClassifierLSTM(history_size, history_dim, y_dim,\n","                               rnn_layers = rnn_layers, rnn_neurons = rnn_neurons,\n","                               dense_layers = dnn_layers, dense_neurons = dnn_neurons) \n","    model.load_weights(save_path)\n","    \n","    prediction = model.predict(test_x, verbose=0)\n","    prediction = prediction.round(0).astype(int)\n","\n","    y_real = test_y\n","    y_pred = prediction\n","    \n","    accuracy  = 100*np.array(accuracy_score(y_real, y_pred)).round(4)\n","    precision = 100*np.array(precision_score(y_real, y_pred, average=None)).round(4)[1]\n","    recall    = 100*np.array(recall_score(y_real, y_pred, average=None)).round(4)[1]\n","    f1        = 100*np.array(f1_score(y_real, y_pred, average=None)).round(4)[1]\n","    \n","    accuracy_list.append(accuracy)\n","    precision_list.append(precision)\n","    recall_list.append(recall)\n","    f1_list.append(f1)\n","    \n","accuracies = np.array(accuracy_list)\n","precisions = np.array(precision_list)\n","recalls = np.array(recall_list)\n","f1s = np.array(f1_list)\n","\n","results = pd.DataFrame(np.array([accuracies, precisions, recalls, f1s]).T, columns=['accuracy', 'precision', 'recall', 'f1-score'])\n","results.describe()"],"id":"473d2f8b"},{"cell_type":"code","source":[],"metadata":{"id":"j70ztt7mCdhI"},"id":"j70ztt7mCdhI","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"toc_visible":true,"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"384px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":5}